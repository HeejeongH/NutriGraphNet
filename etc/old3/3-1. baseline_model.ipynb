{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aea14639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda'\n"
     ]
    }
   ],
   "source": [
    "from utils import get_health_scores, recall_at_k_binary, ndcg_at_k_binary, heterograph_to_tabular\n",
    "from sklearn.decomposition import NMF\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e683e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== Starting fold 0 ===========\n"
     ]
    }
   ],
   "source": [
    "def load_fold_data(fold_path):\n",
    "    with open(fold_path, 'rb') as f:\n",
    "        fold_data = pickle.load(f)\n",
    "    return fold_data['train_data'], fold_data['val_data'], fold_data['test_data'], fold_data['health_dict']\n",
    "\n",
    "# Load the fold data\n",
    "fold = 0\n",
    "fold_path = os.path.join('../data/processed_data', f'fold_{fold+1}.pkl')\n",
    "print(f\"\\n=========== Starting fold {fold} ===========\")\n",
    "\n",
    "train_data, val_data, test_data, health_dict = load_fold_data(fold_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019a7871",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edge_index = test_data['user', 'eats', 'food'].edge_label_index\n",
    "test_health_scores = get_health_scores(test_edge_index, health_dict, device='cpu').cpu().numpy()\n",
    "\n",
    "X_train, y_train = heterograph_to_tabular(train_data)\n",
    "X_test, y_test = heterograph_to_tabular(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ce4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *\n",
    "\n",
    "# PyCaret 설정\n",
    "clf = setup(pd.concat([X_train, y_train], axis=1), target='label', \n",
    "           session_id=42, train_size=0.8, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187ffe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    }
   ],
   "source": [
    "# 모델 비교 및 학습\n",
    "models = ['rf', 'gbc', 'knn', 'lr', 'lightgbm', 'dt', 'svm', 'mlp', 'xgboost'] # ''rbfsvm',\n",
    "best_models = {}\n",
    "\n",
    "for model_name in models:\n",
    "    model = create_model(model_name, verbose=False)\n",
    "    tuned_model = tune_model(model, verbose=False)\n",
    "    finalized_model = finalize_model(tuned_model)\n",
    "    \n",
    "    # 예측\n",
    "    y_pred_proba = predict_model(finalized_model, data=X_test)['prediction_label']\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    # 커스텀 메트릭 계산\n",
    "    metrics = {\n",
    "        'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'ndcg@10': ndcg_at_k_binary(y_test, y_pred_proba, 10),\n",
    "        'recall@10': recall_at_k_binary(y_test, y_pred_proba, 10),\n",
    "        'ndcg@20': ndcg_at_k_binary(y_test, y_pred_proba, 20),\n",
    "        'recall@20': recall_at_k_binary(y_test, y_pred_proba, 20),\n",
    "        'health_score': np.mean(test_health_scores[y_pred_proba > 0.5]) if np.sum(y_pred_proba > 0.5) > 0 else 0.0\n",
    "    }\n",
    "    \n",
    "    best_models[model_name] = {'model': finalized_model, 'metrics': metrics}\n",
    "    \n",
    "    # 모델 저장\n",
    "    save_model(finalized_model, f'baseline_models/fold_{fold+1}_{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fa7740c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "from utils import ndcg_at_k_binary, recall_at_k_binary\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def evaluate_saved_model(model_path, X_test, y_test, test_health_scores):\n",
    "    model_name = model_path.replace('.pkl', '')\n",
    "    model = load_model(model_name)\n",
    "    \n",
    "    predictions = predict_model(model, data=X_test, raw_score=True)\n",
    "    prob_cols = [col for col in predictions.columns if 'score' in col.lower() and '1' in col]\n",
    "    if prob_cols:\n",
    "        y_pred_proba = predictions[prob_cols[0]].values\n",
    "    else:\n",
    "        y_pred_proba = predictions['prediction_label'].astype(float).values\n",
    "    \n",
    "    y_pred = predictions['prediction_label'].values\n",
    "    \n",
    "    return {\n",
    "        'index': 0,\n",
    "        'test_auc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'test_accuracy': accuracy_score(y_test, y_pred),\n",
    "        'test_precision': precision_score(y_test, y_pred),\n",
    "        'test_recall': recall_score(y_test, y_pred),\n",
    "        'test_f1': f1_score(y_test, y_pred),\n",
    "        'test_ndcg@10': ndcg_at_k_binary(y_test, y_pred_proba, 10),\n",
    "        'test_recall@10': recall_at_k_binary(y_test, y_pred_proba, 10),\n",
    "        'test_ndcg@20': ndcg_at_k_binary(y_test, y_pred_proba, 20),\n",
    "        'test_recall@20': recall_at_k_binary(y_test, y_pred_proba, 20),\n",
    "        'test_health_score': np.mean(test_health_scores[y_pred_proba > 0.5]) if np.sum(y_pred_proba > 0.5) > 0 else 0.0\n",
    "    }\n",
    "\n",
    "# 모든 저장된 모델 평가\n",
    "results = {}\n",
    "for model_file in glob.glob('baseline_models/fold_*.pkl'):\n",
    "    model_name = os.path.basename(model_file).replace('.pkl', '')\n",
    "    results[model_name] = evaluate_saved_model(model_file, X_test, y_test, test_health_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34e20bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('baseline_models/evaluation_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704cc558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization(fold, train_data, test_data, health_dict):\n",
    "    \n",
    "    \n",
    "    _, y_test = heterograph_to_tabular(test_data)\n",
    "    \n",
    "    user_indices = train_data['user', 'eats', 'food'].edge_label_index[0].cpu().numpy()\n",
    "    food_indices = train_data['user', 'eats', 'food'].edge_label_index[1].cpu().numpy()\n",
    "    ratings = train_data['user', 'eats', 'food'].edge_label.cpu().numpy()\n",
    "    \n",
    "    unique_users = np.unique(user_indices)\n",
    "    unique_foods = np.unique(food_indices)\n",
    "    \n",
    "    user_id_map = {old_id: new_id for new_id, old_id in enumerate(unique_users)}\n",
    "    food_id_map = {old_id: new_id for new_id, old_id in enumerate(unique_foods)}\n",
    "    \n",
    "    mapped_user_indices = np.array([user_id_map[idx] for idx in user_indices])\n",
    "    mapped_food_indices = np.array([food_id_map[idx] for idx in food_indices])\n",
    "    \n",
    "    from scipy.sparse import csr_matrix\n",
    "    matrix_shape = (len(unique_users), len(unique_foods))\n",
    "    ratings_matrix = csr_matrix((ratings, (mapped_user_indices, mapped_food_indices)), shape=matrix_shape)\n",
    "    \n",
    "    nmf_model = NMF(n_components=20, random_state=42)\n",
    "    user_factors = nmf_model.fit_transform(ratings_matrix)\n",
    "    item_factors = nmf_model.components_\n",
    "    \n",
    "    test_user_indices = test_data['user', 'eats', 'food'].edge_label_index[0].cpu().numpy()\n",
    "    test_food_indices = test_data['user', 'eats', 'food'].edge_label_index[1].cpu().numpy()\n",
    "    test_edge_index = test_data['user', 'eats', 'food'].edge_label_index\n",
    "    test_health_scores = get_health_scores(test_edge_index, health_dict, device='cpu').cpu().numpy()\n",
    "    \n",
    "    mf_predictions = []\n",
    "    for u, f in zip(test_user_indices, test_food_indices):\n",
    "        if u not in user_id_map or f not in food_id_map:\n",
    "            mf_predictions.append(0.5)\n",
    "        else:\n",
    "            mapped_u = user_id_map[u]\n",
    "            mapped_f = food_id_map[f]\n",
    "            pred = np.dot(user_factors[mapped_u], item_factors[:, mapped_f])\n",
    "            mf_predictions.append(min(max(pred / 5.0, 0), 1))\n",
    "    \n",
    "    mf_predictions = np.array(mf_predictions)\n",
    "    \n",
    "    mf_binary_predictions = (mf_predictions >= 0.5).astype(int)\n",
    "    metrics = {\n",
    "        'auc': roc_auc_score(y_test, mf_predictions),\n",
    "        'accuracy': accuracy_score(y_test, mf_binary_predictions),\n",
    "        'precision': precision_score(y_test, mf_binary_predictions),\n",
    "        'recall': recall_score(y_test, mf_binary_predictions),\n",
    "        'f1': f1_score(y_test, mf_binary_predictions),\n",
    "        'recall@10' : recall_at_k_binary(y_test, mf_predictions, 10),\n",
    "        'recall@20' : recall_at_k_binary(y_test, mf_predictions, 20),\n",
    "        'ndcg@10': ndcg_at_k_binary(y_test, mf_predictions, 10),\n",
    "        'ndcg@20': ndcg_at_k_binary(y_test, mf_predictions, 20)\n",
    "    }\n",
    "    \n",
    "    mask = mf_binary_predictions == 1\n",
    "    if np.sum(mask) > 0:\n",
    "        metrics['health_score'] = np.mean(test_health_scores[mask])\n",
    "    else:\n",
    "        metrics['health_score'] = 0.0\n",
    "    \n",
    "    print(f\"Matrix Factorization - Test AUC: {metrics['auc']:.4f}, F1: {metrics['f1']:.4f}, Health Score: {metrics['health_score']:.4f}\")\n",
    "    \n",
    "    os.makedirs('mf_models', exist_ok=True)\n",
    "    with open(f'mf_models/fold_{fold+1}_best_model.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'user_factors': user_factors,\n",
    "            'item_factors': item_factors,\n",
    "            'user_id_map': user_id_map,\n",
    "            'food_id_map': food_id_map,\n",
    "            'test_metrics': metrics,\n",
    "            'predictions': mf_predictions\n",
    "        }, f)\n",
    "    \n",
    "    return {'MatrixFactorization': metrics}, {'MatrixFactorization': mf_predictions}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
