{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 0.14 GB\n",
      "Cached: 0.23 GB\n"
     ]
    }
   ],
   "source": [
    "# 즉시 실행\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# 다시 확인\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "print(f\"Cached: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   디바이스: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HeteroConv, GATConv, GCNConv, SAGEConv, GraphConv\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device('cuda')  # PyTorch Geometric MPS 호환성 문제로 CPU 사용\n",
    "torch.set_num_threads(8)\n",
    "\n",
    "print(f\"   디바이스: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   사용자 수: 20,820\n",
      "   음식 수: 31,458\n",
      "   그래프 엣지 타입: [('user', 'eats', 'food'), ('food', 'contains', 'ingredient'), ('food', 'eaten_at', 'time'), ('user', 'healthness', 'food'), ('food', 'similar', 'food'), ('food', 'rev_eats', 'user'), ('ingredient', 'rev_contains', 'food'), ('time', 'rev_eaten_at', 'food'), ('food', 'rev_healthness', 'user')]\n",
      "   노드 타입: ['user', 'food', 'ingredient', 'time']\n",
      "   user 특성: torch.Size([20820, 29])\n",
      "   food 특성: torch.Size([31458, 17])\n",
      "   ingredient 특성: torch.Size([3284, 101])\n",
      "   time 특성: torch.Size([4, 4])\n",
      "   건강 관계: 262,270개\n",
      "   건강 점수 범위: [0.295, 0.958]\n"
     ]
    }
   ],
   "source": [
    "class CPUUnpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else:\n",
    "            return super().find_class(module, name)\n",
    "\n",
    "# 데이터 로드\n",
    "data_path = '../data/processed_data/processed_data_GNN.pkl'\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# GPU로 이동\n",
    "data = data.to('cuda')\n",
    "\n",
    "print(f\"   사용자 수: {len(data.user_id_mapping):,}\")\n",
    "print(f\"   음식 수: {len(data.food_id_mapping):,}\")\n",
    "print(f\"   그래프 엣지 타입: {list(data.edge_index_dict.keys())}\")\n",
    "print(f\"   노드 타입: {list(data.x_dict.keys())}\")\n",
    "\n",
    "for node_type, features in data.x_dict.items():\n",
    "    print(f\"   {node_type} 특성: {features.shape}\")\n",
    "\n",
    "if ('user', 'healthness', 'food') in data.edge_index_dict:\n",
    "    health_edges = data[('user', 'healthness', 'food')].edge_index.shape[1]\n",
    "    health_scores = data[('user', 'healthness', 'food')].edge_attr\n",
    "    print(f\"   건강 관계: {health_edges:,}개\")\n",
    "    print(f\"   건강 점수 범위: [{health_scores.min():.3f}, {health_scores.max():.3f}]\")\n",
    "else:\n",
    "    print(\"   ❌ healthness 엣지를 찾을 수 없음\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Traditional ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ml_data(data, sample_size=50000):\n",
    "    eats_edge_index = data[('user', 'eats', 'food')].edge_index\n",
    "    eats_edge_attr = data[('user', 'eats', 'food')].edge_attr\n",
    "\n",
    "    user_indices = eats_edge_index[0].cpu().numpy()\n",
    "    food_indices = eats_edge_index[1].cpu().numpy()\n",
    "    eats_scores = eats_edge_attr.cpu().numpy()\n",
    "\n",
    "    user_features = data.x_dict['user'].cpu().numpy()\n",
    "    food_features = data.x_dict['food'].cpu().numpy()\n",
    "\n",
    "    # 샘플링\n",
    "    sample_indices = np.random.choice(len(eats_scores), min(sample_size, len(eats_scores)), replace=False)\n",
    "    threshold = np.median(eats_scores)\n",
    "\n",
    "    # 특성 결합 및 고급 특성 엔지니어링\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for idx in sample_indices:\n",
    "        user_idx = user_indices[idx]\n",
    "        food_idx = food_indices[idx]\n",
    "        \n",
    "        # 기본 특성\n",
    "        user_feat = user_features[user_idx]\n",
    "        food_feat = food_features[food_idx]\n",
    "        \n",
    "        # 고급 특성 엔지니어링\n",
    "        min_len = min(len(user_feat), len(food_feat))\n",
    "        interaction = user_feat[:min_len] * food_feat[:min_len]\n",
    "        difference = np.abs(user_feat[:min_len] - food_feat[:min_len])\n",
    "        \n",
    "        # 통계 특성\n",
    "        user_stats = [user_feat.mean(), user_feat.std(), user_feat.max(), user_feat.min()]\n",
    "        food_stats = [food_feat.mean(), food_feat.std(), food_feat.max(), food_feat.min()]\n",
    "        \n",
    "        # 모든 특성 결합\n",
    "        combined = np.concatenate([\n",
    "            user_feat, food_feat, interaction, difference, user_stats, food_stats\n",
    "        ])\n",
    "        \n",
    "        X.append(combined)\n",
    "        y.append(1 if eats_scores[idx] > threshold else 0)\n",
    "\n",
    "    return np.array(X), np.array(y), threshold, sample_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[256, 128, 64]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        layers.extend([nn.Linear(prev_dim, 1), nn.Sigmoid()])\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class AdvancedMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[512, 256, 128]):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.bn_input = nn.BatchNorm1d(hidden_dims[0])\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], 1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn_input(self.input_layer(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for layer, bn in zip(self.hidden_layers, self.batch_norms):\n",
    "            residual = x\n",
    "            x = F.relu(bn(layer(x)))\n",
    "            x = self.dropout(x)\n",
    "            if x.shape == residual.shape:\n",
    "                x = x + residual\n",
    "\n",
    "        return torch.sigmoid(self.output_layer(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 GNN Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaGNN(nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, metadata, input_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_projections = nn.ModuleDict({\n",
    "            node_type: nn.Linear(input_dims[node_type], hidden_channels)\n",
    "            for node_type in metadata[0]\n",
    "        })\n",
    "\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('user', 'eats', 'food'): GraphConv(hidden_channels, out_channels),\n",
    "            ('food', 'rev_eats', 'user'): GraphConv(hidden_channels, out_channels)\n",
    "        })\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('user', 'eats', 'food'): GraphConv(out_channels, out_channels),\n",
    "            ('food', 'rev_eats', 'user'): GraphConv(out_channels, out_channels)\n",
    "        })\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index, **kwargs):\n",
    "        current_x = {node_type: self.input_projections[node_type](features)\n",
    "                    for node_type, features in x_dict.items()}\n",
    "\n",
    "        current_x = self.conv1(current_x, edge_index_dict)\n",
    "        current_x = {k: F.relu(v) for k, v in current_x.items()}\n",
    "\n",
    "        current_x = self.conv2(current_x, edge_index_dict)\n",
    "        current_x = {k: F.relu(v) for k, v in current_x.items()}\n",
    "\n",
    "        user_indices, food_indices = edge_label_index\n",
    "        user_emb = current_x['user'][user_indices]\n",
    "        food_emb = current_x['food'][food_indices]\n",
    "\n",
    "        combined = torch.cat([user_emb, food_emb], dim=-1)\n",
    "        return self.decoder(combined).squeeze()\n",
    "\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, metadata, input_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_projections = nn.ModuleDict({\n",
    "            node_type: nn.Linear(input_dims[node_type], hidden_channels)\n",
    "            for node_type in metadata[0]\n",
    "        })\n",
    "\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('user', 'eats', 'food'): SAGEConv(hidden_channels, out_channels),\n",
    "            ('food', 'rev_eats', 'user'): SAGEConv(hidden_channels, out_channels)\n",
    "        })\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('user', 'eats', 'food'): SAGEConv(out_channels, out_channels),\n",
    "            ('food', 'rev_eats', 'user'): SAGEConv(out_channels, out_channels)\n",
    "        })\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index, **kwargs):\n",
    "        current_x = {node_type: self.input_projections[node_type](features)\n",
    "                    for node_type, features in x_dict.items()}\n",
    "\n",
    "        current_x = self.conv1(current_x, edge_index_dict)\n",
    "        current_x = {k: F.relu(v) for k, v in current_x.items()}\n",
    "\n",
    "        current_x = self.conv2(current_x, edge_index_dict)\n",
    "        current_x = {k: F.relu(v) for k, v in current_x.items()}\n",
    "\n",
    "        user_indices, food_indices = edge_label_index\n",
    "        user_emb = current_x['user'][user_indices]\n",
    "        food_emb = current_x['food'][food_indices]\n",
    "\n",
    "        combined = torch.cat([user_emb, food_emb], dim=-1)\n",
    "        return self.decoder(combined).squeeze()\n",
    "\n",
    "class GAT_NoHealth(nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, metadata, input_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_projections = nn.ModuleDict({\n",
    "            node_type: nn.Linear(input_dims[node_type], hidden_channels)\n",
    "            for node_type in metadata[0]\n",
    "        })\n",
    "\n",
    "        self.conv = HeteroConv({\n",
    "            ('user', 'eats', 'food'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False, edge_dim=1\n",
    "            ),\n",
    "            ('food', 'rev_eats', 'user'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False\n",
    "            )\n",
    "        })\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.batch_norms = nn.ModuleDict({\n",
    "            node_type: nn.BatchNorm1d(out_channels) for node_type in metadata[0]\n",
    "        })\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index, **kwargs):\n",
    "        current_x = {node_type: self.input_projections[node_type](features)\n",
    "                    for node_type, features in x_dict.items()}\n",
    "\n",
    "        current_x = self.conv(current_x, edge_index_dict)\n",
    "\n",
    "        for node_type in current_x.keys():\n",
    "            if node_type in self.batch_norms:\n",
    "                current_x[node_type] = F.relu(self.batch_norms[node_type](current_x[node_type]))\n",
    "\n",
    "        user_indices, food_indices = edge_label_index\n",
    "        user_emb = current_x['user'][user_indices]\n",
    "        food_emb = current_x['food'][food_indices]\n",
    "\n",
    "        combined = torch.cat([user_emb, food_emb], dim=-1)\n",
    "        return self.decoder(combined).squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Ablation Study Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HealthAware_NoAttention(nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, metadata, input_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_projections = nn.ModuleDict({\n",
    "            node_type: nn.Linear(input_dims[node_type], hidden_channels)\n",
    "            for node_type in metadata[0]\n",
    "        })\n",
    "\n",
    "        self.conv = HeteroConv({\n",
    "            ('user', 'eats', 'food'): GraphConv(hidden_channels, out_channels),\n",
    "            ('food', 'rev_eats', 'user'): GraphConv(hidden_channels, out_channels)\n",
    "        })\n",
    "\n",
    "        # 간단한 건강 선호도 네트워크 (어텐션 없음)\n",
    "        self.health_preference_net = nn.Sequential(\n",
    "            nn.Linear(out_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index,\n",
    "                health_edge_index=None, health_scores=None, training=True):\n",
    "\n",
    "        current_x = {node_type: self.input_projections[node_type](features)\n",
    "                    for node_type, features in x_dict.items()}\n",
    "\n",
    "        current_x = self.conv(current_x, edge_index_dict)\n",
    "        current_x = {k: F.relu(v) for k, v in current_x.items()}\n",
    "\n",
    "        # 간단한 건강 정보 통합 (어텐션 없음)\n",
    "        if health_edge_index is not None and health_scores is not None:\n",
    "            user_embeddings = current_x['user']\n",
    "            user_health_prefs = self.health_preference_net(user_embeddings)\n",
    "\n",
    "            avg_health = health_scores.mean()\n",
    "            health_scale = 0.1 * avg_health\n",
    "            current_x['food'] = current_x['food'] + health_scale\n",
    "\n",
    "        user_indices, food_indices = edge_label_index\n",
    "        user_emb = current_x['user'][user_indices]\n",
    "        food_emb = current_x['food'][food_indices]\n",
    "\n",
    "        combined = torch.cat([user_emb, food_emb], dim=-1)\n",
    "        return self.decoder(combined).squeeze()\n",
    "\n",
    "class HealthAware_NoLoss(nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, metadata, input_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_projections = nn.ModuleDict({\n",
    "            node_type: nn.Linear(input_dims[node_type], hidden_channels)\n",
    "            for node_type in metadata[0]\n",
    "        })\n",
    "\n",
    "        self.conv = HeteroConv({\n",
    "            ('user', 'eats', 'food'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False, edge_dim=1\n",
    "            ),\n",
    "            ('food', 'rev_eats', 'user'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False\n",
    "            )\n",
    "        })\n",
    "\n",
    "        self.health_preference_net = nn.Sequential(\n",
    "            nn.Linear(out_channels, out_channels // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.batch_norms = nn.ModuleDict({\n",
    "            node_type: nn.BatchNorm1d(out_channels) for node_type in metadata[0]\n",
    "        })\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index,\n",
    "                health_edge_index=None, health_scores=None, training=True):\n",
    "\n",
    "        current_x = {node_type: self.input_projections[node_type](features)\n",
    "                    for node_type, features in x_dict.items()}\n",
    "\n",
    "        current_x = self.conv(current_x, edge_index_dict)\n",
    "\n",
    "        for node_type in current_x.keys():\n",
    "            if node_type in self.batch_norms:\n",
    "                current_x[node_type] = F.relu(self.batch_norms[node_type](current_x[node_type]))\n",
    "\n",
    "        # 건강 어텐션 (손실 없이)\n",
    "        if health_edge_index is not None and health_scores is not None:\n",
    "            user_embeddings = current_x['user']\n",
    "            food_embeddings = current_x['food']\n",
    "\n",
    "            user_health_prefs = self.health_preference_net(user_embeddings)\n",
    "\n",
    "            user_indices_health = health_edge_index[0]\n",
    "            food_indices_health = health_edge_index[1]\n",
    "\n",
    "            personal_weights = user_health_prefs[user_indices_health].squeeze()\n",
    "            enhanced_health = torch.sigmoid(health_scores * 2.0)\n",
    "            final_weights = personal_weights * enhanced_health\n",
    "\n",
    "            health_updates = scatter(\n",
    "                final_weights, food_indices_health, dim=0,\n",
    "                dim_size=food_embeddings.size(0), reduce='mean'\n",
    "            )\n",
    "\n",
    "            health_scale = 0.2\n",
    "            health_expanded = health_updates.unsqueeze(1).expand(-1, current_x['food'].size(1))\n",
    "            current_x['food'] = current_x['food'] + health_scale * health_expanded\n",
    "\n",
    "        user_indices, food_indices = edge_label_index\n",
    "        user_emb = current_x['user'][user_indices]\n",
    "        food_emb = current_x['food'][food_indices]\n",
    "\n",
    "        combined = torch.cat([user_emb, food_emb], dim=-1)\n",
    "        return self.decoder(combined).squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 SOTA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEnhancedGNN_Fixed(nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, metadata, input_dims, num_heads=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.input_projections = nn.ModuleDict({\n",
    "            node_type: nn.Linear(input_dims[node_type], hidden_channels)\n",
    "            for node_type in metadata[0]\n",
    "        })\n",
    "        \n",
    "        self.conv = HeteroConv({\n",
    "            ('user', 'eats', 'food'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False, edge_dim=1\n",
    "            ),\n",
    "            ('food', 'rev_eats', 'user'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False\n",
    "            )\n",
    "        })\n",
    "        \n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            embed_dim=out_channels,\n",
    "            num_heads=4,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.pos_encoding = nn.Parameter(torch.randn(1000, out_channels))\n",
    "        self.layer_norm = nn.LayerNorm(out_channels)\n",
    "        \n",
    "        self.health_preference_net = nn.Sequential(\n",
    "            nn.Linear(out_channels, out_channels // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(out_channels, out_channels * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_channels * 2, out_channels),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index, health_edge_index=None, health_scores=None, training=True):\n",
    "        \n",
    "        for node_type, x in x_dict.items():\n",
    "            x_dict[node_type] = self.input_projections[node_type](x)\n",
    "        \n",
    "        x_dict = self.conv(x_dict, edge_index_dict)\n",
    "        \n",
    "        user_embeddings = x_dict['user']\n",
    "        food_embeddings = x_dict['food']\n",
    "        \n",
    "        x_combined = torch.cat([user_embeddings, food_embeddings], dim=0)\n",
    "        \n",
    "        seq_len = x_combined.size(0)\n",
    "        if seq_len <= self.pos_encoding.size(0):\n",
    "            pos_enc = self.pos_encoding[:seq_len]\n",
    "            x_combined = x_combined + pos_enc\n",
    "        \n",
    "        x_norm = self.layer_norm(x_combined)\n",
    "        \n",
    "        x_expanded = x_norm.unsqueeze(0)\n",
    "        attn_out, _ = self.multihead_attn(x_expanded, x_expanded, x_expanded)\n",
    "        x_attn = attn_out.squeeze(0)\n",
    "        \n",
    "        x_residual = x_norm + x_attn\n",
    "        \n",
    "        x_ffn = self.ffn(x_residual)\n",
    "        x_output = x_residual + x_ffn\n",
    "        \n",
    "        n_users = user_embeddings.size(0)\n",
    "        x_dict['user'] = x_output[:n_users]\n",
    "        x_dict['food'] = x_output[n_users:]\n",
    "        \n",
    "        user_indices, food_indices = edge_label_index\n",
    "        user_emb = x_dict['user'][user_indices]\n",
    "        food_emb = x_dict['food'][food_indices]\n",
    "        \n",
    "        edge_emb = torch.cat([user_emb, food_emb], dim=1)\n",
    "        predictions = self.decoder(edge_emb).squeeze()\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "class ContrastiveLearningGNN(nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, metadata, input_dims, temperature=0.07):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.temperature = temperature\n",
    "        \n",
    "        self.input_projections = nn.ModuleDict({\n",
    "            node_type: nn.Linear(input_dims[node_type], hidden_channels)\n",
    "            for node_type in metadata[0]\n",
    "        })\n",
    "        \n",
    "        # 기본 인코더\n",
    "        self.encoder = HeteroConv({\n",
    "            ('user', 'eats', 'food'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False, edge_dim=1\n",
    "            ),\n",
    "            ('food', 'rev_eats', 'user'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False\n",
    "            )\n",
    "        })\n",
    "        \n",
    "        # Contrastive projection heads\n",
    "        self.user_projector = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, 64)\n",
    "        )\n",
    "        \n",
    "        self.food_projector = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, 64)\n",
    "        )\n",
    "        \n",
    "        # Health-aware projector\n",
    "        self.health_projector = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_channels // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels // 2, 32)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.batch_norms = nn.ModuleDict({\n",
    "            node_type: nn.BatchNorm1d(out_channels) for node_type in metadata[0]\n",
    "        })\n",
    "\n",
    "    def contrastive_loss(self, user_proj, food_proj, positive_pairs):\n",
    "        \"\"\"InfoNCE 대조 손실 계산\"\"\"\n",
    "        # L2 normalize\n",
    "        user_proj = F.normalize(user_proj, dim=-1)\n",
    "        food_proj = F.normalize(food_proj, dim=-1)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        similarity = torch.matmul(user_proj, food_proj.T) / self.temperature\n",
    "        \n",
    "        # Create positive mask\n",
    "        batch_size = user_proj.size(0)\n",
    "        positive_mask = torch.zeros(batch_size, batch_size, device=user_proj.device)\n",
    "        for i, j in positive_pairs:\n",
    "            if i < batch_size and j < batch_size:\n",
    "                positive_mask[i, j] = 1\n",
    "        \n",
    "        # InfoNCE loss\n",
    "        exp_sim = torch.exp(similarity)\n",
    "        pos_exp_sim = exp_sim * positive_mask\n",
    "        neg_exp_sim = exp_sim * (1 - positive_mask)\n",
    "        \n",
    "        pos_sum = pos_exp_sim.sum(dim=1, keepdim=True).clamp(min=1e-8)\n",
    "        neg_sum = neg_exp_sim.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        loss = -torch.log(pos_sum / (pos_sum + neg_sum)).mean()\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index,\n",
    "                health_edge_index=None, health_scores=None, training=True):\n",
    "        \n",
    "        current_x = {node_type: self.input_projections[node_type](features)\n",
    "                    for node_type, features in x_dict.items()}\n",
    "        \n",
    "        current_x = self.encoder(current_x, edge_index_dict)\n",
    "        \n",
    "        for node_type in current_x.keys():\n",
    "            if node_type in self.batch_norms:\n",
    "                current_x[node_type] = F.relu(self.batch_norms[node_type](current_x[node_type]))\n",
    "        \n",
    "        # 건강 정보 통합\n",
    "        if health_edge_index is not None and health_scores is not None:\n",
    "            user_embeddings = current_x['user']\n",
    "            food_embeddings = current_x['food']\n",
    "            \n",
    "            # Health-aware enhancement\n",
    "            user_health_proj = self.health_projector(user_embeddings)\n",
    "            food_health_proj = self.health_projector(food_embeddings)\n",
    "            \n",
    "            user_indices_health = health_edge_index[0]\n",
    "            food_indices_health = health_edge_index[1]\n",
    "            \n",
    "            health_enhanced = torch.sigmoid(health_scores * 2.0)\n",
    "            health_updates = scatter(\n",
    "                health_enhanced, food_indices_health, dim=0,\n",
    "                dim_size=food_embeddings.size(0), reduce='mean'\n",
    "            )\n",
    "            \n",
    "            health_scale = 0.25\n",
    "            health_expanded = health_updates.unsqueeze(1).expand(-1, current_x['food'].size(1))\n",
    "            current_x['food'] = current_x['food'] + health_scale * health_expanded\n",
    "        \n",
    "        user_indices, food_indices = edge_label_index\n",
    "        user_emb = current_x['user'][user_indices]\n",
    "        food_emb = current_x['food'][food_indices]\n",
    "        \n",
    "        # Store projections for contrastive learning\n",
    "        if training:\n",
    "            self.user_projections = self.user_projector(user_emb)\n",
    "            self.food_projections = self.food_projector(food_emb)\n",
    "        \n",
    "        combined = torch.cat([user_emb, food_emb], dim=-1)\n",
    "        return self.decoder(combined).squeeze()\n",
    "\n",
    "class MetaLearningGNN(nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, metadata, input_dims):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_projections = nn.ModuleDict({\n",
    "            node_type: nn.Linear(input_dims[node_type], hidden_channels)\n",
    "            for node_type in metadata[0]\n",
    "        })\n",
    "        \n",
    "        # Meta-learnable base network\n",
    "        self.meta_conv = HeteroConv({\n",
    "            ('user', 'eats', 'food'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False, edge_dim=1\n",
    "            ),\n",
    "            ('food', 'rev_eats', 'user'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False\n",
    "            )\n",
    "        })\n",
    "        \n",
    "        # Personal adaptation networks\n",
    "        self.user_adaptation = nn.Sequential(\n",
    "            nn.Linear(out_channels, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "        self.food_adaptation = nn.Sequential(\n",
    "            nn.Linear(out_channels, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "        # Health personalization network\n",
    "        self.health_personalization = nn.Sequential(\n",
    "            nn.Linear(out_channels + 1, out_channels),  # +1 for health score\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels, out_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Dynamic decoder (personalized)\n",
    "        self.meta_decoder = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Personal preference learning\n",
    "        self.preference_embedding = nn.Embedding(10000, 32)  # User preference embeddings\n",
    "        self.preference_fusion = nn.Linear(out_channels + 32, out_channels)\n",
    "\n",
    "    def adapt_to_user(self, user_embeddings, user_history=None):\n",
    "        \"\"\"사용자별 적응형 임베딩 생성\"\"\"\n",
    "        adapted_user = self.user_adaptation(user_embeddings)\n",
    "        \n",
    "        # Add personal preference if available\n",
    "        if user_history is not None:\n",
    "            pref_emb = self.preference_embedding(user_history)\n",
    "            combined = torch.cat([adapted_user, pref_emb], dim=-1)\n",
    "            adapted_user = self.preference_fusion(combined)\n",
    "        \n",
    "        return adapted_user\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index,\n",
    "                health_edge_index=None, health_scores=None, training=True, user_history=None):\n",
    "        \n",
    "        current_x = {node_type: self.input_projections[node_type](features)\n",
    "                    for node_type, features in x_dict.items()}\n",
    "        \n",
    "        current_x = self.meta_conv(current_x, edge_index_dict)\n",
    "        current_x = {k: F.relu(v) for k, v in current_x.items()}\n",
    "        \n",
    "        # Personal adaptation\n",
    "        current_x['user'] = self.adapt_to_user(current_x['user'], user_history)\n",
    "        current_x['food'] = self.food_adaptation(current_x['food'])\n",
    "        \n",
    "        # Health-aware personalization\n",
    "        if health_edge_index is not None and health_scores is not None:\n",
    "            user_embeddings = current_x['user']\n",
    "            food_embeddings = current_x['food']\n",
    "            \n",
    "            user_indices_health = health_edge_index[0]\n",
    "            food_indices_health = health_edge_index[1]\n",
    "            \n",
    "            # Personal health preferences\n",
    "            health_context = torch.cat([\n",
    "                food_embeddings[food_indices_health],\n",
    "                health_scores.unsqueeze(1)\n",
    "            ], dim=1)\n",
    "            \n",
    "            personal_health_weights = self.health_personalization(health_context)\n",
    "            \n",
    "            health_updates = scatter(\n",
    "                personal_health_weights.squeeze(), food_indices_health, dim=0,\n",
    "                dim_size=food_embeddings.size(0), reduce='mean'\n",
    "            )\n",
    "            \n",
    "            health_scale = 0.2\n",
    "            current_x['food'] = current_x['food'] * (1 + health_scale * health_updates.unsqueeze(1))\n",
    "        \n",
    "        user_indices, food_indices = edge_label_index\n",
    "        user_emb = current_x['user'][user_indices]\n",
    "        food_emb = current_x['food'][food_indices]\n",
    "        \n",
    "        combined = torch.cat([user_emb, food_emb], dim=-1)\n",
    "        return self.meta_decoder(combined).squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.5. Multi-Task Learning Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskHealthGNN(nn.Module):\n",
    "    \"\"\"멀티태스크 학습 프레임워크 (추천 + 건강예측 + 영양분석)\"\"\"\n",
    "    def __init__(self, hidden_channels, out_channels, metadata, input_dims):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_projections = nn.ModuleDict({\n",
    "            node_type: nn.Linear(input_dims[node_type], hidden_channels)\n",
    "            for node_type in metadata[0]\n",
    "        })\n",
    "        \n",
    "        # Shared feature extractor\n",
    "        self.shared_encoder = HeteroConv({\n",
    "            ('user', 'eats', 'food'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False, edge_dim=1\n",
    "            ),\n",
    "            ('food', 'rev_eats', 'user'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False\n",
    "            )\n",
    "        })\n",
    "        \n",
    "        # Task-specific heads\n",
    "        # Task 1: Preference Prediction (Main task)\n",
    "        self.preference_head = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Task 2: Health Score Prediction\n",
    "        self.health_prediction_head = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels, 1)  # Regression for health score\n",
    "        )\n",
    "        \n",
    "        # Task 3: Nutritional Category Classification\n",
    "        self.nutrition_classification_head = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels, 5),  # 5 nutritional categories\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        # Task 4: User Health Risk Assessment\n",
    "        self.health_risk_head = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_channels // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels // 2, 3),  # Low, Medium, High risk\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        # Health-aware attention with multi-task context\n",
    "        self.health_attention = nn.MultiheadAttention(\n",
    "            embed_dim=out_channels,\n",
    "            num_heads=4,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Task balancing weights (learnable)\n",
    "        self.task_weights = nn.Parameter(torch.ones(4))\n",
    "        \n",
    "        self.batch_norms = nn.ModuleDict({\n",
    "            node_type: nn.BatchNorm1d(out_channels) for node_type in metadata[0]\n",
    "        })\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index,\n",
    "                health_edge_index=None, health_scores=None, training=True, return_all_tasks=False):\n",
    "        \n",
    "        current_x = {node_type: self.input_projections[node_type](features)\n",
    "                    for node_type, features in x_dict.items()}\n",
    "        \n",
    "        # Shared encoding\n",
    "        current_x = self.shared_encoder(current_x, edge_index_dict)\n",
    "        \n",
    "        for node_type in current_x.keys():\n",
    "            if node_type in self.batch_norms:\n",
    "                current_x[node_type] = F.relu(self.batch_norms[node_type](current_x[node_type]))\n",
    "        \n",
    "        # Health-aware processing\n",
    "        if health_edge_index is not None and health_scores is not None:\n",
    "            user_embeddings = current_x['user']\n",
    "            food_embeddings = current_x['food']\n",
    "            \n",
    "            # Multi-task health attention\n",
    "            user_exp = user_embeddings.unsqueeze(0)\n",
    "            food_exp = food_embeddings.unsqueeze(0)\n",
    "            \n",
    "            health_attn_out, _ = self.health_attention(user_exp, food_exp, food_exp)\n",
    "            enhanced_user = health_attn_out.squeeze(0)\n",
    "            \n",
    "            # Health integration\n",
    "            user_indices_health = health_edge_index[0]\n",
    "            food_indices_health = health_edge_index[1]\n",
    "            \n",
    "            health_weights = torch.sigmoid(health_scores * 2.0)\n",
    "            health_updates = scatter(\n",
    "                health_weights, food_indices_health, dim=0,\n",
    "                dim_size=food_embeddings.size(0), reduce='mean'\n",
    "            )\n",
    "            \n",
    "            health_scale = 0.25\n",
    "            health_expanded = health_updates.unsqueeze(1).expand(-1, current_x['food'].size(1))\n",
    "            current_x['food'] = current_x['food'] + health_scale * health_expanded\n",
    "            current_x['user'] = enhanced_user\n",
    "        \n",
    "        user_indices, food_indices = edge_label_index\n",
    "        user_emb = current_x['user'][user_indices]\n",
    "        food_emb = current_x['food'][food_indices]\n",
    "        \n",
    "        # Task 1: Preference Prediction (Main)\n",
    "        combined = torch.cat([user_emb, food_emb], dim=-1)\n",
    "        preference_pred = self.preference_head(combined).squeeze()\n",
    "        \n",
    "        if not return_all_tasks:\n",
    "            return preference_pred\n",
    "        \n",
    "        # All tasks for multi-task training\n",
    "        tasks_output = {}\n",
    "        \n",
    "        # Task 1: Preference (already computed)\n",
    "        tasks_output['preference'] = preference_pred\n",
    "        \n",
    "        # Task 2: Health Score Prediction\n",
    "        tasks_output['health_score'] = self.health_prediction_head(combined).squeeze()\n",
    "        \n",
    "        # Task 3: Nutritional Classification (food-based)\n",
    "        tasks_output['nutrition_category'] = self.nutrition_classification_head(food_emb)\n",
    "        \n",
    "        # Task 4: User Health Risk (user-based)\n",
    "        tasks_output['health_risk'] = self.health_risk_head(user_emb)\n",
    "        \n",
    "        return tasks_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.6. Self-Supervised Pre-training GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfSupervisedGNN(nn.Module):\n",
    "    \"\"\"자기지도 학습 기반 사전훈련 GNN (GraphMAE/SimGRACE 스타일)\"\"\"\n",
    "    def __init__(self, hidden_channels, out_channels, metadata, input_dims, mask_ratio=0.15):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mask_ratio = mask_ratio\n",
    "        \n",
    "        self.input_projections = nn.ModuleDict({\n",
    "            node_type: nn.Linear(input_dims[node_type], hidden_channels)\n",
    "            for node_type in metadata[0]\n",
    "        })\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = HeteroConv({\n",
    "            ('user', 'eats', 'food'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False, edge_dim=1\n",
    "            ),\n",
    "            ('food', 'rev_eats', 'user'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False\n",
    "            )\n",
    "        })\n",
    "        \n",
    "        # Decoder for reconstruction\n",
    "        self.decoder = nn.ModuleDict({\n",
    "            node_type: nn.Sequential(\n",
    "                nn.Linear(out_channels, hidden_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_channels, input_dims[node_type])\n",
    "            ) for node_type in metadata[0]\n",
    "        })\n",
    "        \n",
    "        # Contrastive projection\n",
    "        self.contrastive_projector = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, 128)\n",
    "        )\n",
    "        \n",
    "        # Health-aware components\n",
    "        self.health_attention = nn.MultiheadAttention(\n",
    "            embed_dim=out_channels,\n",
    "            num_heads=4,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Final task head (for downstream task)\n",
    "        self.task_head = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.batch_norms = nn.ModuleDict({\n",
    "            node_type: nn.BatchNorm1d(out_channels) for node_type in metadata[0]\n",
    "        })\n",
    "\n",
    "    def mask_features(self, x_dict):\n",
    "        \"\"\"특성 마스킹 (자기지도 학습용)\"\"\"\n",
    "        masked_x = {}\n",
    "        masks = {}\n",
    "        \n",
    "        for node_type, features in x_dict.items():\n",
    "            mask = torch.rand(features.shape, device=features.device) < self.mask_ratio\n",
    "            masked_features = features.clone()\n",
    "            masked_features[mask] = 0  # 마스킹된 부분을 0으로 설정\n",
    "            \n",
    "            masked_x[node_type] = masked_features\n",
    "            masks[node_type] = mask\n",
    "        \n",
    "        return masked_x, masks\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index=None,\n",
    "                health_edge_index=None, health_scores=None, training=True, \n",
    "                pretraining=False):\n",
    "        \n",
    "        if pretraining:\n",
    "            # Self-supervised pre-training mode\n",
    "            masked_x, masks = self.mask_features(x_dict)\n",
    "            current_x = {node_type: self.input_projections[node_type](features)\n",
    "                        for node_type, features in masked_x.items()}\n",
    "        else:\n",
    "            # Downstream task mode\n",
    "            current_x = {node_type: self.input_projections[node_type](features)\n",
    "                        for node_type, features in x_dict.items()}\n",
    "        \n",
    "        # Encoding\n",
    "        current_x = self.encoder(current_x, edge_index_dict)\n",
    "        \n",
    "        for node_type in current_x.keys():\n",
    "            if node_type in self.batch_norms:\n",
    "                current_x[node_type] = F.relu(self.batch_norms[node_type](current_x[node_type]))\n",
    "        \n",
    "        if pretraining:\n",
    "            # Return reconstructions and contrastive features for pre-training\n",
    "            reconstructions = {}\n",
    "            for node_type in current_x.keys():\n",
    "                reconstructions[node_type] = self.decoder[node_type](current_x[node_type])\n",
    "            \n",
    "            contrastive_features = {\n",
    "                node_type: self.contrastive_projector(emb) \n",
    "                for node_type, emb in current_x.items()\n",
    "            }\n",
    "            \n",
    "            return {\n",
    "                'reconstructions': reconstructions,\n",
    "                'contrastive_features': contrastive_features,\n",
    "                'masks': masks,\n",
    "                'original_features': x_dict\n",
    "            }\n",
    "        \n",
    "        # Downstream task mode\n",
    "        # Health-aware processing\n",
    "        if health_edge_index is not None and health_scores is not None:\n",
    "            user_embeddings = current_x['user']\n",
    "            food_embeddings = current_x['food']\n",
    "            \n",
    "            user_exp = user_embeddings.unsqueeze(0)\n",
    "            food_exp = food_embeddings.unsqueeze(0)\n",
    "            \n",
    "            health_attn_out, _ = self.health_attention(user_exp, food_exp, food_exp)\n",
    "            enhanced_user = health_attn_out.squeeze(0)\n",
    "            \n",
    "            user_indices_health = health_edge_index[0]\n",
    "            food_indices_health = health_edge_index[1]\n",
    "            \n",
    "            health_weights = torch.sigmoid(health_scores * 2.0)\n",
    "            health_updates = scatter(\n",
    "                health_weights, food_indices_health, dim=0,\n",
    "                dim_size=food_embeddings.size(0), reduce='mean'\n",
    "            )\n",
    "            \n",
    "            health_scale = 0.2\n",
    "            health_expanded = health_updates.unsqueeze(1).expand(-1, current_x['food'].size(1))\n",
    "            current_x['food'] = current_x['food'] + health_scale * health_expanded\n",
    "            current_x['user'] = enhanced_user\n",
    "        \n",
    "        # Task prediction\n",
    "        if edge_label_index is not None:\n",
    "            user_indices, food_indices = edge_label_index\n",
    "            user_emb = current_x['user'][user_indices]\n",
    "            food_emb = current_x['food'][food_indices]\n",
    "            \n",
    "            combined = torch.cat([user_emb, food_emb], dim=-1)\n",
    "            return self.task_head(combined).squeeze()\n",
    "        \n",
    "        return current_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullHealthAwareGNN(nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, metadata, input_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_projections = nn.ModuleDict({\n",
    "            node_type: nn.Linear(input_dims[node_type], hidden_channels)\n",
    "            for node_type in metadata[0]\n",
    "        })\n",
    "\n",
    "        self.conv = HeteroConv({\n",
    "            ('user', 'eats', 'food'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False, edge_dim=1\n",
    "            ),\n",
    "            ('food', 'rev_eats', 'user'): GATConv(\n",
    "                in_channels=(-1, -1), out_channels=out_channels,\n",
    "                heads=4, concat=False, dropout=0.3, add_self_loops=False\n",
    "            )\n",
    "        })\n",
    "\n",
    "        # 🌟 핵심 혁신: 건강 어텐션 메커니즘 🌟\n",
    "        self.health_preference_net = nn.Sequential(\n",
    "            nn.Linear(out_channels, out_channels // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.batch_norms = nn.ModuleDict({\n",
    "            node_type: nn.BatchNorm1d(out_channels) for node_type in metadata[0]\n",
    "        })\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index,\n",
    "                health_edge_index=None, health_scores=None, training=True):\n",
    "\n",
    "        current_x = {node_type: self.input_projections[node_type](features)\n",
    "                    for node_type, features in x_dict.items()}\n",
    "\n",
    "        current_x = self.conv(current_x, edge_index_dict)\n",
    "\n",
    "        for node_type in current_x.keys():\n",
    "            if node_type in self.batch_norms:\n",
    "                current_x[node_type] = F.relu(self.batch_norms[node_type](current_x[node_type]))\n",
    "\n",
    "        # 🌟 완전한 건강 인식 처리 🌟\n",
    "        if health_edge_index is not None and health_scores is not None:\n",
    "            user_embeddings = current_x['user']\n",
    "            food_embeddings = current_x['food']\n",
    "\n",
    "            # 개인화된 건강 선호도\n",
    "            user_health_prefs = self.health_preference_net(user_embeddings)\n",
    "\n",
    "            # 건강 정보 통합\n",
    "            user_indices_health = health_edge_index[0]\n",
    "            food_indices_health = health_edge_index[1]\n",
    "\n",
    "            personal_weights = user_health_prefs[user_indices_health].squeeze()\n",
    "            enhanced_health = torch.sigmoid(health_scores * 2.0)\n",
    "            final_weights = personal_weights * enhanced_health\n",
    "\n",
    "            health_updates = scatter(\n",
    "                final_weights, food_indices_health, dim=0,\n",
    "                dim_size=food_embeddings.size(0), reduce='mean'\n",
    "            )\n",
    "\n",
    "            # 건강 정보를 음식 표현에 통합\n",
    "            health_scale = 0.2\n",
    "            health_expanded = health_updates.unsqueeze(1).expand(-1, current_x['food'].size(1))\n",
    "            current_x['food'] = current_x['food'] + health_scale * health_expanded\n",
    "\n",
    "        user_indices, food_indices = edge_label_index\n",
    "        user_emb = current_x['user'][user_indices]\n",
    "        food_emb = current_x['food'][food_indices]\n",
    "\n",
    "        combined = torch.cat([user_emb, food_emb], dim=-1)\n",
    "        predictions = self.decoder(combined).squeeze()\n",
    "\n",
    "        # 🌟 추론 시 건강한 선택 유도 🌟\n",
    "        if not training and health_edge_index is not None:\n",
    "            predictions = torch.sigmoid(torch.logit(predictions + 1e-7) + 0.1)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "class GraphTransformerNetwork(nn.Module):\n",
    "    \"\"\"그래프 트랜스포머 네트워크 (GT/GraphiT 스타일)\"\"\"\n",
    "    def __init__(self, hidden_channels, out_channels, metadata, input_dims, num_layers=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.input_projections = nn.ModuleDict({\n",
    "            node_type: nn.Linear(input_dims[node_type], hidden_channels)\n",
    "            for node_type in metadata[0]\n",
    "        })\n",
    "        \n",
    "        # Graph Transformer layers\n",
    "        self.gt_layers = nn.ModuleList([\n",
    "            GraphTransformerLayer(hidden_channels, num_heads=8)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Edge encoding for different edge types\n",
    "        self.edge_encoders = nn.ModuleDict({\n",
    "            'eats': nn.Linear(1, hidden_channels),\n",
    "            'healthness': nn.Linear(1, hidden_channels),\n",
    "            'default': nn.Linear(1, hidden_channels)\n",
    "        })\n",
    "        \n",
    "        # Health-aware graph attention\n",
    "        self.health_graph_attn = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_channels,\n",
    "            num_heads=4,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Final projection to output dimension\n",
    "        self.output_projection = nn.Linear(hidden_channels, out_channels)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, hidden_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels, hidden_channels // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_channels // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index,\n",
    "                health_edge_index=None, health_scores=None, training=True):\n",
    "        \n",
    "        # Input projection and combine all node types\n",
    "        all_nodes = []\n",
    "        node_type_map = {}\n",
    "        offset = 0\n",
    "        \n",
    "        for node_type, features in x_dict.items():\n",
    "            projected = self.input_projections[node_type](features)\n",
    "            all_nodes.append(projected)\n",
    "            node_type_map[node_type] = (offset, offset + features.size(0))\n",
    "            offset += features.size(0)\n",
    "        \n",
    "        combined_nodes = torch.cat(all_nodes, dim=0)\n",
    "        \n",
    "        # Process through Graph Transformer layers\n",
    "        for gt_layer in self.gt_layers:\n",
    "            combined_nodes = gt_layer(combined_nodes, edge_index_dict, node_type_map)\n",
    "        \n",
    "        # Project to output dimension\n",
    "        combined_nodes = self.output_projection(combined_nodes)\n",
    "        \n",
    "        # Split back to individual node types\n",
    "        current_x = {}\n",
    "        for node_type, (start, end) in node_type_map.items():\n",
    "            current_x[node_type] = combined_nodes[start:end]\n",
    "        \n",
    "        # Health-aware processing\n",
    "        if health_edge_index is not None and health_scores is not None:\n",
    "            user_embeddings = current_x['user']\n",
    "            food_embeddings = current_x['food']\n",
    "            \n",
    "            # Health-aware graph attention\n",
    "            user_exp = user_embeddings.unsqueeze(0)\n",
    "            food_exp = food_embeddings.unsqueeze(0)\n",
    "            \n",
    "            health_attn_out, _ = self.health_graph_attn(user_exp, food_exp, food_exp)\n",
    "            enhanced_user = health_attn_out.squeeze(0)\n",
    "            \n",
    "            # Health integration\n",
    "            user_indices_health = health_edge_index[0]\n",
    "            food_indices_health = health_edge_index[1]\n",
    "            \n",
    "            health_weights = torch.sigmoid(health_scores * 2.5)\n",
    "            health_updates = scatter(\n",
    "                health_weights, food_indices_health, dim=0,\n",
    "                dim_size=food_embeddings.size(0), reduce='mean'\n",
    "            )\n",
    "            \n",
    "            health_scale = 0.35\n",
    "            health_expanded = health_updates.unsqueeze(1).expand(-1, current_x['food'].size(1))\n",
    "            current_x['food'] = current_x['food'] + health_scale * health_expanded\n",
    "            current_x['user'] = enhanced_user\n",
    "        \n",
    "        user_indices, food_indices = edge_label_index\n",
    "        user_emb = current_x['user'][user_indices]\n",
    "        food_emb = current_x['food'][food_indices]\n",
    "        \n",
    "        combined = torch.cat([user_emb, food_emb], dim=-1)\n",
    "        return self.decoder(combined).squeeze()\n",
    "\n",
    "class GraphTransformerLayer(nn.Module):\n",
    "    \"\"\"단일 그래프 트랜스포머 레이어\"\"\"\n",
    "    def __init__(self, hidden_dim, num_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, edge_index_dict, node_type_map):\n",
    "        # Self-attention with residual connection\n",
    "        x_norm = self.norm1(x)\n",
    "        x_expanded = x_norm.unsqueeze(0)\n",
    "        attn_out, _ = self.attention(x_expanded, x_expanded, x_expanded)\n",
    "        x = x + self.dropout(attn_out.squeeze(0))\n",
    "        \n",
    "        # Feed forward with residual connection\n",
    "        x_norm = self.norm2(x)\n",
    "        ff_out = self.feed_forward(x_norm)\n",
    "        x = x + self.dropout(ff_out)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(self, predictions, targets, **kwargs):\n",
    "        return self.bce(predictions, targets)\n",
    "\n",
    "class HealthAwareLoss(nn.Module):\n",
    "    def __init__(self, health_lambda=0.1):\n",
    "        super().__init__()\n",
    "        self.health_lambda = health_lambda\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(self, predictions, targets, health_scores=None):\n",
    "        base_loss = self.bce(predictions, targets)\n",
    "\n",
    "        if health_scores is not None and len(health_scores) > 0:\n",
    "            # 건강한 음식일수록 높은 예측값을 가지도록 정규화\n",
    "            health_normalized = torch.sigmoid(health_scores)\n",
    "            health_reg = -torch.mean(predictions * health_normalized.mean())\n",
    "            total_loss = base_loss + self.health_lambda * health_reg\n",
    "        else:\n",
    "            total_loss = base_loss\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, predictions, targets, user_proj=None, food_proj=None, **kwargs):\n",
    "        base_loss = F.binary_cross_entropy(predictions, targets)\n",
    "        \n",
    "        if user_proj is not None and food_proj is not None:\n",
    "            # InfoNCE contrastive loss\n",
    "            user_proj = F.normalize(user_proj, dim=-1)\n",
    "            food_proj = F.normalize(food_proj, dim=-1)\n",
    "            \n",
    "            similarity = torch.matmul(user_proj, food_proj.T) / self.temperature\n",
    "            labels = torch.arange(similarity.size(0), device=similarity.device)\n",
    "            \n",
    "            contrastive_loss = F.cross_entropy(similarity, labels)\n",
    "            return base_loss + 0.1 * contrastive_loss\n",
    "        \n",
    "        return base_loss\n",
    "\n",
    "class MultiTaskLoss(nn.Module):\n",
    "    def __init__(self, task_weights=None):\n",
    "        super().__init__()\n",
    "        self.task_weights = task_weights or {'preference': 1.0, 'health_score': 0.5, \n",
    "                                           'nutrition_category': 0.3, 'health_risk': 0.2}\n",
    "        self.bce = nn.BCELoss()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, predictions, targets, **kwargs):\n",
    "        if isinstance(predictions, dict):\n",
    "            # Multi-task mode\n",
    "            total_loss = 0\n",
    "            \n",
    "            # Task 1: Preference prediction\n",
    "            if 'preference' in predictions and 'preference' in targets:\n",
    "                pref_loss = self.bce(predictions['preference'], targets['preference'])\n",
    "                total_loss += self.task_weights['preference'] * pref_loss\n",
    "            \n",
    "            # Task 2: Health score prediction  \n",
    "            if 'health_score' in predictions and 'health_score' in targets:\n",
    "                health_loss = self.mse(predictions['health_score'], targets['health_score'])\n",
    "                total_loss += self.task_weights['health_score'] * health_loss\n",
    "            \n",
    "            # Task 3: Nutrition classification\n",
    "            if 'nutrition_category' in predictions and 'nutrition_category' in targets:\n",
    "                nutrition_loss = self.ce(predictions['nutrition_category'], targets['nutrition_category'])\n",
    "                total_loss += self.task_weights['nutrition_category'] * nutrition_loss\n",
    "            \n",
    "            # Task 4: Health risk assessment\n",
    "            if 'health_risk' in predictions and 'health_risk' in targets:\n",
    "                risk_loss = self.ce(predictions['health_risk'], targets['health_risk'])\n",
    "                total_loss += self.task_weights['health_risk'] * risk_loss\n",
    "            \n",
    "            return total_loss\n",
    "        else:\n",
    "            # Single task mode\n",
    "            return self.bce(predictions, targets)\n",
    "\n",
    "class SelfSupervisedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # Balance between reconstruction and contrastive\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, predictions, targets=None, **kwargs):\n",
    "        if isinstance(predictions, dict) and 'reconstructions' in predictions:\n",
    "            # Self-supervised pre-training mode\n",
    "            reconstructions = predictions['reconstructions']\n",
    "            original_features = predictions['original_features']\n",
    "            masks = predictions['masks']\n",
    "            contrastive_features = predictions['contrastive_features']\n",
    "            \n",
    "            # Reconstruction loss (only on masked parts)\n",
    "            recon_loss = 0\n",
    "            for node_type in reconstructions.keys():\n",
    "                mask = masks[node_type]\n",
    "                recon = reconstructions[node_type]\n",
    "                original = original_features[node_type]\n",
    "                \n",
    "                masked_recon_loss = self.mse(recon[mask], original[mask])\n",
    "                recon_loss += masked_recon_loss\n",
    "            \n",
    "            # Contrastive loss between different node types\n",
    "            contrastive_loss = 0\n",
    "            if 'user' in contrastive_features and 'food' in contrastive_features:\n",
    "                user_feat = F.normalize(contrastive_features['user'], dim=-1)\n",
    "                food_feat = F.normalize(contrastive_features['food'], dim=-1)\n",
    "                \n",
    "                # Simple contrastive loss\n",
    "                similarity = torch.matmul(user_feat, food_feat.T)\n",
    "                positive_pairs = torch.eye(min(user_feat.size(0), food_feat.size(0)), \n",
    "                                         device=user_feat.device)\n",
    "                contrastive_loss = -torch.sum(positive_pairs * similarity) / positive_pairs.sum()\n",
    "            \n",
    "            return self.alpha * recon_loss + (1 - self.alpha) * contrastive_loss\n",
    "        else:\n",
    "            # Standard supervised loss\n",
    "            return F.binary_cross_entropy(predictions, targets)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, predictions, targets, **kwargs):\n",
    "        ce_loss = F.binary_cross_entropy(predictions, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "class AdvancedHealthAwareLoss(nn.Module):\n",
    "    def __init__(self, health_lambda=0.1, diversity_lambda=0.05, consistency_lambda=0.02):\n",
    "        super().__init__()\n",
    "        self.health_lambda = health_lambda\n",
    "        self.diversity_lambda = diversity_lambda\n",
    "        self.consistency_lambda = consistency_lambda\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(self, predictions, targets, health_scores=None, user_embeddings=None, **kwargs):\n",
    "        base_loss = self.bce(predictions, targets)\n",
    "        \n",
    "        total_loss = base_loss\n",
    "        \n",
    "        # Health regularization\n",
    "        if health_scores is not None and len(health_scores) > 0:\n",
    "            health_normalized = torch.sigmoid(health_scores)\n",
    "            avg_health = health_normalized.mean()\n",
    "            \n",
    "            # Encourage healthy food recommendations\n",
    "            health_reg = -torch.mean(predictions * avg_health)\n",
    "            total_loss += self.health_lambda * health_reg\n",
    "        \n",
    "        # Diversity regularization (encourage diverse recommendations)\n",
    "        if user_embeddings is not None:\n",
    "            # Compute pairwise similarities\n",
    "            normalized_embeddings = F.normalize(user_embeddings, dim=-1)\n",
    "            similarity_matrix = torch.matmul(normalized_embeddings, normalized_embeddings.T)\n",
    "            \n",
    "            # Penalize too similar embeddings (encourage diversity)\n",
    "            diversity_loss = torch.mean(torch.triu(similarity_matrix, diagonal=1) ** 2)\n",
    "            total_loss += self.diversity_lambda * diversity_loss\n",
    "        \n",
    "        # Consistency regularization (predictions should be consistent with health scores)\n",
    "        if health_scores is not None and len(health_scores) > 0:\n",
    "            health_normalized = torch.sigmoid(health_scores * 2.0)\n",
    "            avg_health = health_normalized.mean()\n",
    "            \n",
    "            # Consistency between predictions and health\n",
    "            pred_health_consistency = torch.abs(predictions.mean() - avg_health)\n",
    "            total_loss += self.consistency_lambda * pred_health_consistency\n",
    "        \n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 실험 실행 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_traditional_ml_models(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    models = {\n",
    "        'Logistic_Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'Random_Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'Gradient_Boosting': GradientBoostingClassifier(random_state=42),\n",
    "        #'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "        'SVM': SVC(probability=True, random_state=42, kernel='rbf')\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"   Training {name}...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = model.decision_function(X_test)\n",
    "            # Normalize to [0,1]\n",
    "            y_pred_proba = (y_pred_proba - y_pred_proba.min()) / (y_pred_proba.max() - y_pred_proba.min())\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        results[name] = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "            'training_time': training_time\n",
    "        }\n",
    "\n",
    "        print(f\"     {name}: F1={results[name]['f1']:.3f}, AUC={results[name]['auc']:.3f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def run_deep_learning_models(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    models = {\n",
    "        'Simple_MLP': SimpleMLP(X.shape[1]),\n",
    "        'Advanced_MLP': AdvancedMLP(X.shape[1])\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"   Training {name}...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        model = model.to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "        y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "        X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "\n",
    "        # 훈련\n",
    "        model.train()\n",
    "        for epoch in range(50):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_tensor)\n",
    "            loss = criterion(outputs.squeeze(), y_train_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 평가\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test_tensor)\n",
    "            y_pred_proba = test_outputs.squeeze().cpu().numpy()\n",
    "            y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        results[name] = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "            'training_time': training_time\n",
    "        }\n",
    "\n",
    "        print(f\"     {name}: F1={results[name]['f1']:.3f}, AUC={results[name]['auc']:.3f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def train_gnn_model(model, data, sample_indices, threshold, use_health_loss=True):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 데이터 준비\n",
    "    eats_edge_index = data[('user', 'eats', 'food')].edge_index\n",
    "    eats_edge_attr = data[('user', 'eats', 'food')].edge_attr\n",
    "\n",
    "    user_indices = eats_edge_index[0].cpu().numpy()\n",
    "    food_indices = eats_edge_index[1].cpu().numpy()\n",
    "    eats_scores = eats_edge_attr.cpu().numpy()\n",
    "\n",
    "    user_indices_sample = user_indices[sample_indices]\n",
    "    food_indices_sample = food_indices[sample_indices]\n",
    "    y_sample = (eats_scores[sample_indices] > threshold).astype(int)\n",
    "\n",
    "    # Train-test split\n",
    "    indices = np.arange(len(y_sample))\n",
    "    indices_train, indices_test = train_test_split(\n",
    "        indices, test_size=0.2, random_state=42, stratify=y_sample\n",
    "    )\n",
    "\n",
    "    # 모델 설정\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    if use_health_loss:\n",
    "        criterion = HealthAwareLoss(health_lambda=0.1)\n",
    "    else:\n",
    "        criterion = StandardLoss()\n",
    "\n",
    "    # 데이터 텐서\n",
    "    x_dict = {k: v.to(device) for k, v in data.x_dict.items()}\n",
    "    edge_index_dict = {\n",
    "        ('user', 'eats', 'food'): data[('user', 'eats', 'food')].edge_index.to(device),\n",
    "        ('food', 'rev_eats', 'user'): torch.stack([\n",
    "            data[('user', 'eats', 'food')].edge_index[1],\n",
    "            data[('user', 'eats', 'food')].edge_index[0]\n",
    "        ]).to(device)\n",
    "    }\n",
    "\n",
    "    health_edge_index = data[('user', 'healthness', 'food')].edge_index.to(device)\n",
    "    health_scores_tensor = data[('user', 'healthness', 'food')].edge_attr.to(device)\n",
    "\n",
    "    # 훈련\n",
    "    model.train()\n",
    "    for epoch in range(40):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_edge_index = torch.stack([\n",
    "            torch.tensor(user_indices_sample[indices_train], dtype=torch.long),\n",
    "            torch.tensor(food_indices_sample[indices_train], dtype=torch.long)\n",
    "        ]).to(device)\n",
    "        train_targets = torch.tensor(y_sample[indices_train], dtype=torch.float).to(device)\n",
    "\n",
    "        predictions = model(\n",
    "            x_dict, edge_index_dict, train_edge_index,\n",
    "            health_edge_index=health_edge_index,\n",
    "            health_scores=health_scores_tensor,\n",
    "            training=True\n",
    "        )\n",
    "\n",
    "        if use_health_loss:\n",
    "            loss = criterion(predictions, train_targets, health_scores_tensor)\n",
    "        else:\n",
    "            loss = criterion(predictions, train_targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 평가\n",
    "    model.eval()\n",
    "    test_edge_index = torch.stack([\n",
    "        torch.tensor(user_indices_sample[indices_test], dtype=torch.long),\n",
    "        torch.tensor(food_indices_sample[indices_test], dtype=torch.long)\n",
    "    ]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_predictions = model(\n",
    "            x_dict, edge_index_dict, test_edge_index,\n",
    "            health_edge_index=health_edge_index,\n",
    "            health_scores=health_scores_tensor,\n",
    "            training=False\n",
    "        )\n",
    "\n",
    "        y_pred_proba = test_predictions.cpu().numpy()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "    y_test = y_sample[indices_test]\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'training_time': training_time\n",
    "    }\n",
    "\n",
    "def train_enhanced_gnn_model(model, data, sample_indices, threshold, model_type='enhanced'):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 데이터 준비\n",
    "    eats_edge_index = data[('user', 'eats', 'food')].edge_index\n",
    "    eats_edge_attr = data[('user', 'eats', 'food')].edge_attr\n",
    "\n",
    "    user_indices = eats_edge_index[0].cpu().numpy()\n",
    "    food_indices = eats_edge_index[1].cpu().numpy()\n",
    "    eats_scores = eats_edge_attr.cpu().numpy()\n",
    "\n",
    "    user_indices_sample = user_indices[sample_indices]\n",
    "    food_indices_sample = food_indices[sample_indices]\n",
    "    y_sample = (eats_scores[sample_indices] > threshold).astype(int)\n",
    "\n",
    "    # Train-test split\n",
    "    indices = np.arange(len(y_sample))\n",
    "    indices_train, indices_test = train_test_split(\n",
    "        indices, test_size=0.2, random_state=42, stratify=y_sample\n",
    "    )\n",
    "\n",
    "    # 모델 설정\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 고급 옵티마이저 (AdamW + 학습률 스케줄링)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6)\n",
    "    \n",
    "    # 손실 함수 선택\n",
    "    if model_type == 'contrastive':\n",
    "        criterion = ContrastiveLoss(temperature=0.07)\n",
    "    elif model_type == 'multitask':\n",
    "        criterion = MultiTaskLoss()\n",
    "    elif model_type == 'self_supervised':\n",
    "        criterion = SelfSupervisedLoss(alpha=0.6)\n",
    "    elif model_type == 'focal':\n",
    "        criterion = FocalLoss(alpha=1, gamma=2)\n",
    "    else:\n",
    "        criterion = AdvancedHealthAwareLoss(health_lambda=0.15, diversity_lambda=0.05)\n",
    "\n",
    "    # 데이터 텐서\n",
    "    x_dict = {k: v.to(device) for k, v in data.x_dict.items()}\n",
    "    edge_index_dict = {\n",
    "        ('user', 'eats', 'food'): data[('user', 'eats', 'food')].edge_index.to(device),\n",
    "        ('food', 'rev_eats', 'user'): torch.stack([\n",
    "            data[('user', 'eats', 'food')].edge_index[1],\n",
    "            data[('user', 'eats', 'food')].edge_index[0]\n",
    "        ]).to(device)\n",
    "    }\n",
    "    \n",
    "    health_edge_index = data[('user', 'healthness', 'food')].edge_index.to(device)\n",
    "    health_scores_tensor = data[('user', 'healthness', 'food')].edge_attr.to(device)\n",
    "\n",
    "    # Early stopping\n",
    "    best_loss = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "\n",
    "    # 훈련 (더 많은 에포크로 개선)\n",
    "    model.train()\n",
    "    for epoch in range(60):  # 증가된 에포크\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_edge_index = torch.stack([\n",
    "            torch.tensor(user_indices_sample[indices_train], dtype=torch.long),\n",
    "            torch.tensor(food_indices_sample[indices_train], dtype=torch.long)\n",
    "        ]).to(device)\n",
    "        train_targets = torch.tensor(y_sample[indices_train], dtype=torch.float).to(device)\n",
    "\n",
    "        # 모델별 특별 처리\n",
    "        if model_type == 'multitask':\n",
    "            predictions = model(\n",
    "                x_dict, edge_index_dict, train_edge_index,\n",
    "                health_edge_index=health_edge_index,\n",
    "                health_scores=health_scores_tensor,\n",
    "                training=True,\n",
    "                return_all_tasks=True\n",
    "            )\n",
    "            \n",
    "            # 멀티태스크 타겟 생성 (간단한 예시)\n",
    "            targets_dict = {\n",
    "                'preference': train_targets,\n",
    "                'health_score': health_scores_tensor[:len(train_targets)],  # 예시\n",
    "                'nutrition_category': torch.randint(0, 5, (len(train_targets),), device=device),  # 예시\n",
    "                'health_risk': torch.randint(0, 3, (len(train_targets),), device=device)  # 예시\n",
    "            }\n",
    "            \n",
    "            loss = criterion(predictions, targets_dict)\n",
    "            \n",
    "        elif model_type == 'contrastive':\n",
    "            predictions = model(\n",
    "                x_dict, edge_index_dict, train_edge_index,\n",
    "                health_edge_index=health_edge_index,\n",
    "                health_scores=health_scores_tensor,\n",
    "                training=True\n",
    "            )\n",
    "            \n",
    "            # Contrastive projections 사용\n",
    "            user_proj = getattr(model, 'user_projections', None)\n",
    "            food_proj = getattr(model, 'food_projections', None)\n",
    "            \n",
    "            loss = criterion(predictions, train_targets, \n",
    "                           user_proj=user_proj, food_proj=food_proj)\n",
    "            \n",
    "        else:\n",
    "            predictions = model(\n",
    "                x_dict, edge_index_dict, train_edge_index,\n",
    "                health_edge_index=health_edge_index,\n",
    "                health_scores=health_scores_tensor,\n",
    "                training=True\n",
    "            )\n",
    "            \n",
    "            # 사용자 임베딩 추출 (diversity regularization용)\n",
    "            user_embeddings = None\n",
    "            if hasattr(model, 'get_user_embeddings'):\n",
    "                user_embeddings = model.get_user_embeddings(x_dict, edge_index_dict)\n",
    "            \n",
    "            loss = criterion(predictions, train_targets, \n",
    "                           health_scores=health_scores_tensor,\n",
    "                           user_embeddings=user_embeddings)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping (안정성 향상)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Early stopping 체크\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"      Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # 평가\n",
    "    model.eval()\n",
    "    test_edge_index = torch.stack([\n",
    "        torch.tensor(user_indices_sample[indices_test], dtype=torch.long),\n",
    "        torch.tensor(food_indices_sample[indices_test], dtype=torch.long)\n",
    "    ]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if model_type == 'multitask':\n",
    "            test_predictions_dict = model(\n",
    "                x_dict, edge_index_dict, test_edge_index,\n",
    "                health_edge_index=health_edge_index,\n",
    "                health_scores=health_scores_tensor,\n",
    "                training=False,\n",
    "                return_all_tasks=True\n",
    "            )\n",
    "            test_predictions = test_predictions_dict['preference']\n",
    "        else:\n",
    "            test_predictions = model(\n",
    "                x_dict, edge_index_dict, test_edge_index,\n",
    "                health_edge_index=health_edge_index,\n",
    "                health_scores=health_scores_tensor,\n",
    "                training=False\n",
    "            )\n",
    "\n",
    "        y_pred_proba = test_predictions.cpu().numpy()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "    y_test = y_sample[indices_test]\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'training_time': training_time,\n",
    "        'final_loss': best_loss\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 종합 실험 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 데이터 준비 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 Health-Aware GNN Comprehensive Experiments 🔬\n",
      "======================================================================\n",
      "📊 실험 설정:\n",
      "   샘플 크기: 50,000\n",
      "   Random Seed: 42\n",
      "   디바이스: cuda\n",
      "\n",
      "📊 ML 데이터 준비 중...\n",
      "✅ 데이터 준비 완료:\n",
      "   특성 차원: 88\n",
      "   샘플 수: 50,000\n",
      "   임계값 (중앙값): 0.667\n",
      "   Positive 비율: 0.492\n",
      "\n",
      "📊 GNN 메타데이터:\n",
      "   노드 타입: ['user', 'food', 'ingredient', 'time']\n",
      "   엣지 타입 수: 9\n",
      "   user 특성 차원: 29\n",
      "   food 특성 차원: 17\n",
      "   ingredient 특성 차원: 101\n",
      "   time 특성 차원: 4\n"
     ]
    }
   ],
   "source": [
    "# 실험 설정\n",
    "SAMPLE_SIZE = 50000  # 실험 샘플 크기\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "print(\"🔬 Health-Aware GNN Comprehensive Experiments 🔬\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"📊 실험 설정:\")\n",
    "print(f\"   샘플 크기: {SAMPLE_SIZE:,}\")\n",
    "print(f\"   Random Seed: {RANDOM_SEED}\")\n",
    "print(f\"   디바이스: {device}\")\n",
    "\n",
    "# ML 데이터 준비\n",
    "print(\"\\n📊 ML 데이터 준비 중...\")\n",
    "X, y, threshold, sample_indices = prepare_ml_data(data, SAMPLE_SIZE)\n",
    "\n",
    "print(f\"✅ 데이터 준비 완료:\")\n",
    "print(f\"   특성 차원: {X.shape[1]}\")\n",
    "print(f\"   샘플 수: {len(y):,}\")\n",
    "print(f\"   임계값 (중앙값): {threshold:.3f}\")\n",
    "print(f\"   Positive 비율: {y.mean():.3f}\")\n",
    "\n",
    "# GNN 메타데이터 준비\n",
    "metadata = (list(data.x_dict.keys()), list(data.edge_index_dict.keys()))\n",
    "input_dims = {node_type: features.shape[1] for node_type, features in data.x_dict.items()}\n",
    "\n",
    "print(f\"\\n📊 GNN 메타데이터:\")\n",
    "print(f\"   노드 타입: {metadata[0]}\")\n",
    "print(f\"   엣지 타입 수: {len(metadata[1])}\")\n",
    "for node_type, dim in input_dims.items():\n",
    "    print(f\"   {node_type} 특성 차원: {dim}\")\n",
    "\n",
    "# 결과 저장용 딕셔너리\n",
    "all_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Traditional ML Models 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 1. TRADITIONAL ML MODELS\n",
      "--------------------------------------------------\n",
      "   Training Logistic_Regression...\n",
      "     Logistic_Regression: F1=0.614, AUC=0.692\n",
      "   Training Random_Forest...\n",
      "     Random_Forest: F1=0.759, AUC=0.850\n",
      "   Training Gradient_Boosting...\n",
      "     Gradient_Boosting: F1=0.733, AUC=0.831\n",
      "   Training XGBoost...\n",
      "     XGBoost: F1=0.761, AUC=0.851\n",
      "   Training SVM...\n",
      "     SVM: F1=0.501, AUC=0.579\n",
      "\n",
      "Traditional ML Results:\n",
      "   Logistic_Regression : F1=0.614, AUC=0.692, Time=4.6s\n",
      "   Random_Forest       : F1=0.759, AUC=0.850, Time=17.2s\n",
      "   Gradient_Boosting   : F1=0.733, AUC=0.831, Time=45.8s\n",
      "   XGBoost             : F1=0.761, AUC=0.851, Time=0.6s\n",
      "   SVM                 : F1=0.501, AUC=0.579, Time=2111.5s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🔹 1. TRADITIONAL ML MODELS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "ml_results = run_traditional_ml_models(X, y)\n",
    "all_results['traditional_ml'] = ml_results\n",
    "\n",
    "print(\"\\nTraditional ML Results:\")\n",
    "for model_name, metrics in ml_results.items():\n",
    "    print(f\"   {model_name:<20}: F1={metrics['f1']:.3f}, AUC={metrics['auc']:.3f}, Time={metrics['training_time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Deep Learning Models 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 2. DEEP LEARNING MODELS\n",
      "--------------------------------------------------\n",
      "   Training Simple_MLP...\n",
      "     Simple_MLP: F1=0.660, AUC=0.452\n",
      "   Training Advanced_MLP...\n",
      "     Advanced_MLP: F1=0.505, AUC=0.606\n",
      "\n",
      "Deep Learning Results:\n",
      "   Simple_MLP          : F1=0.660, AUC=0.452, Time=4.8s\n",
      "   Advanced_MLP        : F1=0.505, AUC=0.606, Time=0.8s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🔹 2. DEEP LEARNING MODELS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "dl_results = run_deep_learning_models(X, y)\n",
    "all_results['deep_learning'] = dl_results\n",
    "\n",
    "print(\"\\nDeep Learning Results:\")\n",
    "for model_name, metrics in dl_results.items():\n",
    "    print(f\"   {model_name:<20}: F1={metrics['f1']:.3f}, AUC={metrics['auc']:.3f}, Time={metrics['training_time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 GNN Baseline Models 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 3. GNN BASELINE MODELS (No Health Awareness)\n",
      "--------------------------------------------------\n",
      "   Training Vanilla_GCN...\n",
      "     Vanilla_GCN: F1=0.000, AUC=0.500, Time=3.3s\n",
      "   Training GraphSAGE...\n",
      "     GraphSAGE: F1=0.660, AUC=0.500, Time=0.7s\n",
      "   Training GAT_NoHealth...\n",
      "     GAT_NoHealth: F1=0.211, AUC=0.537, Time=1.7s\n",
      "\n",
      "📊 GNN Baseline Results:\n",
      "   Vanilla_GCN         : F1=0.000, AUC=0.500, Time=3.3s\n",
      "   GraphSAGE           : F1=0.660, AUC=0.500, Time=0.7s\n",
      "   GAT_NoHealth        : F1=0.211, AUC=0.537, Time=1.7s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🔹 3. GNN BASELINE MODELS (No Health Awareness)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "gnn_models = {\n",
    "    'Vanilla_GCN': VanillaGNN(128, 64, metadata, input_dims),\n",
    "    'GraphSAGE': GraphSAGE(128, 64, metadata, input_dims),\n",
    "    'GAT_NoHealth': GAT_NoHealth(128, 64, metadata, input_dims)\n",
    "}\n",
    "\n",
    "gnn_results = {}\n",
    "\n",
    "for name, model in gnn_models.items():\n",
    "    print(f\"   Training {name}...\")\n",
    "    result = train_gnn_model(model, data, sample_indices, threshold, use_health_loss=False)\n",
    "    gnn_results[name] = result\n",
    "    print(f\"     {name}: F1={result['f1']:.3f}, AUC={result['auc']:.3f}, Time={result['training_time']:.1f}s\")\n",
    "\n",
    "all_results['gnn_baselines'] = gnn_results\n",
    "\n",
    "print(\"\\n📊 GNN Baseline Results:\")\n",
    "for model_name, metrics in gnn_results.items():\n",
    "    print(f\"   {model_name:<20}: F1={metrics['f1']:.3f}, AUC={metrics['auc']:.3f}, Time={metrics['training_time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Ablation Study Models 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 4. ABLATION STUDY MODELS\n",
      "--------------------------------------------------\n",
      "   Training Health_NoAttention...\n",
      "     Health_NoAttention: F1=0.660, AUC=0.500, Time=0.5s\n",
      "   Training Health_NoLoss...\n",
      "     Health_NoLoss: F1=0.121, AUC=0.519, Time=1.5s\n",
      "\n",
      "📊 Ablation Study Results:\n",
      "   Health_NoAttention  : F1=0.660, AUC=0.500, Time=0.5s\n",
      "   Health_NoLoss       : F1=0.121, AUC=0.519, Time=1.5s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🔹 4. ABLATION STUDY MODELS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "ablation_models = {\n",
    "    'Health_NoAttention': HealthAware_NoAttention(128, 64, metadata, input_dims),\n",
    "    'Health_NoLoss': HealthAware_NoLoss(128, 64, metadata, input_dims)\n",
    "}\n",
    "\n",
    "ablation_results = {}\n",
    "\n",
    "for name, model in ablation_models.items():\n",
    "    print(f\"   Training {name}...\")\n",
    "    if 'NoLoss' in name:\n",
    "        result = train_gnn_model(model, data, sample_indices, threshold, use_health_loss=False)\n",
    "    else:\n",
    "        result = train_gnn_model(model, data, sample_indices, threshold, use_health_loss=True)\n",
    "    ablation_results[name] = result\n",
    "    print(f\"     {name}: F1={result['f1']:.3f}, AUC={result['auc']:.3f}, Time={result['training_time']:.1f}s\")\n",
    "\n",
    "all_results['ablation_study'] = ablation_results\n",
    "\n",
    "print(\"\\n📊 Ablation Study Results:\")\n",
    "for model_name, metrics in ablation_results.items():\n",
    "    print(f\"   {model_name:<20}: F1={metrics['f1']:.3f}, AUC={metrics['auc']:.3f}, Time={metrics['training_time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Our Full Health-Aware Model 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 5. SOTA MODELS (수정됨)\n",
      "--------------------------------------------------\n",
      "   Training TransformerEnhanced_GNN...\n",
      "     TransformerEnhanced_GNN: ERROR - CUDA out of memory. Tried to allocate 40.73 GiB (GPU 0; 8.00 GiB total capacity; 868.61 MiB already allocated; 5.24 GiB free; 994.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "   Training ContrastiveLearning_GNN...\n",
      "      Early stopping at epoch 35\n",
      "     ContrastiveLearning_GNN: F1=0.658, AUC=0.532, Time=1.4s\n",
      "   Training MetaLearning_GNN...\n",
      "     MetaLearning_GNN: ERROR - CUDA out of memory. Tried to allocate 235.94 GiB (GPU 0; 8.00 GiB total capacity; 1.08 GiB already allocated; 4.99 GiB free; 1.22 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "   Training GraphTransformer_Net...\n",
      "     GraphTransformer_Net: ERROR - CUDA out of memory. Tried to allocate 92.02 GiB (GPU 0; 8.00 GiB total capacity; 325.66 MiB already allocated; 5.54 GiB free; 696.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "   Training MultiTaskHealth_GNN...\n",
      "     MultiTaskHealth_GNN: ERROR - CUDA out of memory. Tried to allocate 9.76 GiB (GPU 0; 8.00 GiB total capacity; 13.09 GiB already allocated; 0 bytes free; 20.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "   Training SelfSupervised_GNN...\n",
      "     SelfSupervised_GNN: ERROR - CUDA out of memory. Tried to allocate 9.76 GiB (GPU 0; 8.00 GiB total capacity; 13.09 GiB already allocated; 0 bytes free; 20.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n",
      "📊 SOTA Models Results:\n",
      "   TransformerEnhanced_GNN  : F1=0.000, AUC=0.500, Time=0.0s\n",
      "   ContrastiveLearning_GNN  : F1=0.658, AUC=0.532, Time=1.4s\n",
      "   MetaLearning_GNN         : F1=0.000, AUC=0.500, Time=0.0s\n",
      "   GraphTransformer_Net     : F1=0.000, AUC=0.500, Time=0.0s\n",
      "   MultiTaskHealth_GNN      : F1=0.000, AUC=0.500, Time=0.0s\n",
      "   SelfSupervised_GNN       : F1=0.000, AUC=0.500, Time=0.0s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🔹 5. SOTA MODELS (수정됨)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# SOTA 모델들 정의 (수정된 TransformerEnhanced_GNN 사용)\n",
    "sota_models = {\n",
    "    'TransformerEnhanced_GNN': TransformerEnhancedGNN_Fixed(128, 64, metadata, input_dims),\n",
    "    'ContrastiveLearning_GNN': ContrastiveLearningGNN(128, 64, metadata, input_dims), \n",
    "    'MetaLearning_GNN': MetaLearningGNN(128, 64, metadata, input_dims),\n",
    "    'GraphTransformer_Net': GraphTransformerNetwork(128, 64, metadata, input_dims),\n",
    "    'MultiTaskHealth_GNN': MultiTaskHealthGNN(128, 64, metadata, input_dims),\n",
    "    'SelfSupervised_GNN': SelfSupervisedGNN(128, 64, metadata, input_dims)\n",
    "}\n",
    "\n",
    "sota_results = {}\n",
    "\n",
    "for name, model in sota_models.items():\n",
    "    print(f\"   Training {name}...\")\n",
    "    try:\n",
    "        result = train_enhanced_gnn_model(model, data, sample_indices, threshold)\n",
    "        sota_results[name] = result\n",
    "        print(f\"     {name}: F1={result['f1']:.3f}, AUC={result['auc']:.3f}, Time={result['training_time']:.1f}s\")\n",
    "    except Exception as e:\n",
    "        print(f\"     {name}: ERROR - {str(e)}\")\n",
    "        # 에러가 발생한 모델은 기본값으로 저장\n",
    "        sota_results[name] = {\n",
    "            'f1': 0.000, 'auc': 0.500, 'accuracy': 0.000, \n",
    "            'precision': 0.000, 'recall': 0.000, 'training_time': 0.0\n",
    "        }\n",
    "\n",
    "all_results['enhanced_models'] = sota_results\n",
    "\n",
    "print(\"\\n📊 SOTA Models Results:\")\n",
    "for model_name, metrics in sota_results.items():\n",
    "    print(f\"   {model_name:<25}: F1={metrics['f1']:.3f}, AUC={metrics['auc']:.3f}, Time={metrics['training_time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 6. OUR FULL HEALTH-AWARE MODEL\n",
      "--------------------------------------------------\n",
      "   Training Full Health-Aware GNN...\n",
      "     Full_HealthAware_GNN: F1=0.659, AUC=0.528, Time=2.0s\n",
      "\n",
      "🌟 Our Model Results:\n",
      "   Full_HealthAware_GNN : F1=0.659, AUC=0.528, Time=2.0s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🔹 6. OUR FULL HEALTH-AWARE MODEL\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "our_model = FullHealthAwareGNN(128, 64, metadata, input_dims)\n",
    "\n",
    "print(\"   Training Full Health-Aware GNN...\")\n",
    "our_result = train_gnn_model(our_model, data, sample_indices, threshold, use_health_loss=True)\n",
    "\n",
    "our_results = {'Full_HealthAware_GNN': our_result}\n",
    "all_results['our_model'] = our_results\n",
    "\n",
    "print(f\"     Full_HealthAware_GNN: F1={our_result['f1']:.3f}, AUC={our_result['auc']:.3f}, Time={our_result['training_time']:.1f}s\")\n",
    "\n",
    "print(\"\\n🌟 Our Model Results:\")\n",
    "print(f\"   Full_HealthAware_GNN : F1={our_result['f1']:.3f}, AUC={our_result['auc']:.3f}, Time={our_result['training_time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Health Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 7. HEALTH SCORE ANALYSIS\n",
      "--------------------------------------------------\n",
      "   Analyzing health scores...\n",
      "     Health score statistics:\n",
      "       Mean: 0.657\n",
      "       Std:  0.081\n",
      "       Range: [0.295, 0.958]\n",
      "       Median: 0.650\n",
      "     Health-Preference correlation: 0.046\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🔹 7. HEALTH SCORE ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def analyze_health_scores(data, sample_indices):\n",
    "    \"\"\"건강 점수 분석\"\"\"\n",
    "\n",
    "    health_edge_index = data[('user', 'healthness', 'food')].edge_index\n",
    "    health_scores = data[('user', 'healthness', 'food')].edge_attr\n",
    "\n",
    "    eats_edge_index = data[('user', 'eats', 'food')].edge_index\n",
    "    eats_scores = data[('user', 'eats', 'food')].edge_attr\n",
    "\n",
    "    print(\"   Analyzing health scores...\")\n",
    "\n",
    "    # 건강 점수 통계\n",
    "    health_stats = {\n",
    "        'mean': health_scores.mean().item(),\n",
    "        'std': health_scores.std().item(),\n",
    "        'min': health_scores.min().item(),\n",
    "        'max': health_scores.max().item(),\n",
    "        'median': health_scores.median().item()\n",
    "    }\n",
    "\n",
    "    # 선호도-건강도 상관관계\n",
    "    eats_sample = eats_scores[sample_indices].cpu().numpy()\n",
    "\n",
    "    # 샘플된 eats 엣지에 대응하는 건강 점수 찾기\n",
    "    user_indices_sample = eats_edge_index[0][sample_indices].cpu().numpy()\n",
    "    food_indices_sample = eats_edge_index[1][sample_indices].cpu().numpy()\n",
    "\n",
    "    health_user_indices = health_edge_index[0].cpu().numpy()\n",
    "    health_food_indices = health_edge_index[1].cpu().numpy()\n",
    "    health_scores_array = health_scores.cpu().numpy()\n",
    "\n",
    "    # 매칭되는 건강 점수 찾기\n",
    "    matched_health_scores = []\n",
    "    for u, f in zip(user_indices_sample, food_indices_sample):\n",
    "        mask = (health_user_indices == u) & (health_food_indices == f)\n",
    "        if mask.any():\n",
    "            matched_health_scores.append(health_scores_array[mask][0])\n",
    "        else:\n",
    "            matched_health_scores.append(health_stats['mean'])  # 평균값으로 대체\n",
    "\n",
    "    matched_health_scores = np.array(matched_health_scores)\n",
    "\n",
    "    # 상관관계 계산\n",
    "    correlation = np.corrcoef(eats_sample, matched_health_scores)[0, 1]\n",
    "\n",
    "    print(f\"     Health score statistics:\")\n",
    "    print(f\"       Mean: {health_stats['mean']:.3f}\")\n",
    "    print(f\"       Std:  {health_stats['std']:.3f}\")\n",
    "    print(f\"       Range: [{health_stats['min']:.3f}, {health_stats['max']:.3f}]\")\n",
    "    print(f\"       Median: {health_stats['median']:.3f}\")\n",
    "    print(f\"     Health-Preference correlation: {correlation:.3f}\")\n",
    "\n",
    "    return {\n",
    "        'health_stats': health_stats,\n",
    "        'preference_health_correlation': correlation,\n",
    "        'n_health_edges': len(health_scores),\n",
    "        'n_eats_edges': len(eats_scores),\n",
    "        'matched_health_scores': matched_health_scores\n",
    "    }\n",
    "\n",
    "health_analysis = analyze_health_scores(data, sample_indices)\n",
    "all_results['health_analysis'] = health_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 종합 결과 분석 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🏆 COMPREHENSIVE COMPARISON RESULTS (SOTA Enhanced)\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'traditional_ml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m comparison_results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Traditional ML\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, metrics \u001b[38;5;129;01min\u001b[39;00m \u001b[43mall_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraditional_ml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     10\u001b[0m     comparison_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraditional ML\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: model_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_time\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     19\u001b[0m     })\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Deep Learning\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'traditional_ml'"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🏆 COMPREHENSIVE COMPARISON RESULTS (SOTA Enhanced)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 모든 모델 결과 수집 (SOTA 모델 포함)\n",
    "comparison_results = []\n",
    "\n",
    "# Traditional ML\n",
    "for model_name, metrics in all_results['traditional_ml'].items():\n",
    "    comparison_results.append({\n",
    "        'category': 'Traditional ML',\n",
    "        'model': model_name,\n",
    "        'f1': metrics['f1'],\n",
    "        'auc': metrics['auc'],\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'precision': metrics['precision'],\n",
    "        'recall': metrics['recall'],\n",
    "        'training_time': metrics['training_time']\n",
    "    })\n",
    "\n",
    "# Deep Learning\n",
    "for model_name, metrics in all_results['deep_learning'].items():\n",
    "    comparison_results.append({\n",
    "        'category': 'Deep Learning',\n",
    "        'model': model_name,\n",
    "        'f1': metrics['f1'],\n",
    "        'auc': metrics['auc'],\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'precision': metrics['precision'],\n",
    "        'recall': metrics['recall'],\n",
    "        'training_time': metrics['training_time']\n",
    "    })\n",
    "\n",
    "# GNN Baselines\n",
    "for model_name, metrics in all_results['gnn_baselines'].items():\n",
    "    comparison_results.append({\n",
    "        'category': 'GNN Baseline',\n",
    "        'model': model_name,\n",
    "        'f1': metrics['f1'],\n",
    "        'auc': metrics['auc'],\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'precision': metrics['precision'],\n",
    "        'recall': metrics['recall'],\n",
    "        'training_time': metrics['training_time']\n",
    "    })\n",
    "\n",
    "# Ablation Study\n",
    "for model_name, metrics in all_results['ablation_study'].items():\n",
    "    comparison_results.append({\n",
    "        'category': 'Ablation Study',\n",
    "        'model': model_name,\n",
    "        'f1': metrics['f1'],\n",
    "        'auc': metrics['auc'],\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'precision': metrics['precision'],\n",
    "        'recall': metrics['recall'],\n",
    "        'training_time': metrics['training_time']\n",
    "    })\n",
    "\n",
    "# Our Original Model\n",
    "for model_name, metrics in all_results['our_model'].items():\n",
    "    comparison_results.append({\n",
    "        'category': 'Our Original',\n",
    "        'model': model_name,\n",
    "        'f1': metrics['f1'],\n",
    "        'auc': metrics['auc'],\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'precision': metrics['precision'],\n",
    "        'recall': metrics['recall'],\n",
    "        'training_time': metrics['training_time']\n",
    "    })\n",
    "\n",
    "# 🚀 SOTA Enhanced Models\n",
    "for model_name, metrics in all_results['enhanced_models'].items():\n",
    "    comparison_results.append({\n",
    "        'category': '🚀 SOTA Enhanced',\n",
    "        'model': model_name,\n",
    "        'f1': metrics['f1'],\n",
    "        'auc': metrics['auc'],\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'precision': metrics['precision'],\n",
    "        'recall': metrics['recall'],\n",
    "        'training_time': metrics['training_time']\n",
    "    })\n",
    "\n",
    "# DataFrame으로 변환\n",
    "results_df = pd.DataFrame(comparison_results)\n",
    "\n",
    "print(\"📊 Performance Ranking (by F1 Score):\")\n",
    "print(\"-\" * 120)\n",
    "print(f\"{'Rank':<4} {'Category':<20} {'Model':<30} {'F1':<8} {'AUC':<8} {'Acc':<8} {'Prec':<8} {'Rec':<8} {'Time(s)':<8}\")\n",
    "print(\"-\" * 120)\n",
    "\n",
    "# F1 점수로 정렬\n",
    "results_df_sorted = results_df.sort_values('f1', ascending=False).reset_index(drop=True)\n",
    "\n",
    "for i, row in results_df_sorted.iterrows():\n",
    "    rank = i + 1\n",
    "    category_display = row['category'][:19]  # 길이 제한\n",
    "    model_display = row['model'][:29]  # 길이 제한\n",
    "    \n",
    "    # SOTA 모델 하이라이트\n",
    "    if '🚀' in row['category']:\n",
    "        print(f\"🌟{rank:<3} {category_display:<20} {model_display:<30} \"\n",
    "              f\"{row['f1']:<8.3f} {row['auc']:<8.3f} {row['accuracy']:<8.3f} \"\n",
    "              f\"{row['precision']:<8.3f} {row['recall']:<8.3f} {row['training_time']:<8.1f}\")\n",
    "    else:\n",
    "        print(f\"{rank:<4} {category_display:<20} {model_display:<30} \"\n",
    "              f\"{row['f1']:<8.3f} {row['auc']:<8.3f} {row['accuracy']:<8.3f} \"\n",
    "              f\"{row['precision']:<8.3f} {row['recall']:<8.3f} {row['training_time']:<8.1f}\")\n",
    "\n",
    "# 최고 성능 모델들 식별\n",
    "best_overall = results_df_sorted.iloc[0]\n",
    "best_sota = results_df[results_df['category'] == '🚀 SOTA Enhanced'].sort_values('f1', ascending=False).iloc[0] if len(results_df[results_df['category'] == '🚀 SOTA Enhanced']) > 0 else None\n",
    "\n",
    "print(\"-\" * 120)\n",
    "print(f\"🏆 BEST OVERALL: {best_overall['model']} ({best_overall['category']}) - F1: {best_overall['f1']:.3f}\")\n",
    "if best_sota is not None:\n",
    "    print(f\"🚀 BEST SOTA MODEL: {best_sota['model']} - F1: {best_sota['f1']:.3f}\")\n",
    "\n",
    "# 카테고리별 최고 성능\n",
    "print(f\"\\n🥇 Best in Each Category:\")\n",
    "category_best = results_df.loc[results_df.groupby('category')['f1'].idxmax()]\n",
    "for _, row in category_best.iterrows():\n",
    "    print(f\"   {row['category']:<20}: {row['model']:<30} (F1: {row['f1']:.3f})\")\n",
    "\n",
    "# 성능 개선 분석\n",
    "original_best = all_results['our_model']['Full_HealthAware_GNN']['f1']\n",
    "if best_sota is not None:\n",
    "    sota_best = best_sota['f1']\n",
    "    improvement = sota_best - original_best\n",
    "    improvement_pct = (improvement / original_best) * 100\n",
    "    \n",
    "    print(f\"\\n📈 PERFORMANCE IMPROVEMENT:\")\n",
    "    print(f\"   Original Best Model: {original_best:.3f}\")\n",
    "    print(f\"   SOTA Enhanced Best: {sota_best:.3f}\")\n",
    "    print(f\"   Absolute Improvement: {improvement:+.3f}\")\n",
    "    print(f\"   Relative Improvement: {improvement_pct:+.1f}%\")\n",
    "\n",
    "# Top 5 모델들\n",
    "print(f\"\\n🏅 TOP 5 MODELS:\")\n",
    "for i in range(min(5, len(results_df_sorted))):\n",
    "    row = results_df_sorted.iloc[i]\n",
    "    rank = i + 1\n",
    "    print(f\"   {rank}. {row['model']} ({row['category']}) - F1: {row['f1']:.3f}, AUC: {row['auc']:.3f}\")\n",
    "\n",
    "print(f\"\\n💡 KEY INSIGHTS:\")\n",
    "print(f\"   📊 Total Models Tested: {len(results_df_sorted)}\")\n",
    "print(f\"   🚀 SOTA Models Tested: {len(results_df[results_df['category'] == '🚀 SOTA Enhanced'])}\")\n",
    "print(f\"   🏆 Best F1 Score: {results_df_sorted.iloc[0]['f1']:.3f}\")\n",
    "print(f\"   ⚡ Best AUC Score: {results_df_sorted.sort_values('auc', ascending=False).iloc[0]['auc']:.3f}\")\n",
    "\n",
    "# 다분야 기법 효과 분석\n",
    "sota_models = results_df[results_df['category'] == '🚀 SOTA Enhanced']\n",
    "if len(sota_models) > 0:\n",
    "    print(f\"\\n🔬 SOTA TECHNIQUES ANALYSIS:\")\n",
    "    print(f\"   📈 SOTA Average F1: {sota_models['f1'].mean():.3f}\")\n",
    "    print(f\"   📈 SOTA Best F1: {sota_models['f1'].max():.3f}\")\n",
    "    print(f\"   📈 SOTA Models in Top 5: {len([m for m in results_df_sorted.head(5)['category'] if '🚀' in m])}\")\n",
    "    \n",
    "    # 각 SOTA 기법별 성능\n",
    "    print(f\"   🔥 Transformer-based: {sota_models[sota_models['model'].str.contains('Transformer')]['f1'].max():.3f}\")\n",
    "    print(f\"   🎯 Contrastive Learning: {sota_models[sota_models['model'].str.contains('Contrastive')]['f1'].max():.3f}\")\n",
    "    print(f\"   🧠 Meta-Learning: {sota_models[sota_models['model'].str.contains('Meta')]['f1'].max():.3f}\")\n",
    "    print(f\"   🔄 Multi-Task: {sota_models[sota_models['model'].str.contains('MultiTask')]['f1'].max():.3f}\")\n",
    "    print(f\"   🎨 Self-Supervised: {sota_models[sota_models['model'].str.contains('SelfSupervised')]['f1'].max():.3f}\")\n",
    "\n",
    "print(f\"\\n🎉 SOTA Enhancement Complete! Multiple cutting-edge techniques successfully integrated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Count: 1\n",
      "\n",
      "=== GPU 0 ===\n",
      "Name: NVIDIA GeForce RTX 3070\n",
      "Total Memory: 8.59 GB\n",
      "Allocated: 0.14 GB\n",
      "Cached: 22.22 GB\n",
      "Free: -13.63 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 기본 정보\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU Count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"\\n=== GPU {i} ===\")\n",
    "        print(f\"Name: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"Total Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")\n",
    "        print(f\"Allocated: {torch.cuda.memory_allocated(i) / 1e9:.2f} GB\")\n",
    "        print(f\"Cached: {torch.cuda.memory_reserved(i) / 1e9:.2f} GB\")\n",
    "        print(f\"Free: {(torch.cuda.get_device_properties(i).total_memory - torch.cuda.memory_reserved(i)) / 1e9:.2f} GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
