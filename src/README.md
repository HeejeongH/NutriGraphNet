# NutriGraphNet: Health-Aware GNN for Food Recommendation

## ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”

**NutriGraphNet**ì€ ê°œì¸ ë§ì¶¤í˜• ê±´ê°• ìŒì‹ ì¶”ì²œì„ ìœ„í•œ ê·¸ë˜í”„ ì‹ ê²½ë§ ê¸°ë°˜ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê±´ê°• íŠ¹ì„±ê³¼ ì˜ì–‘ ì •ë³´ë¥¼ ê³ ë ¤í•˜ì—¬ ì„ í˜¸ë„ì™€ ê±´ê°•ì„ ë™ì‹œì— ìµœì í™”í•˜ëŠ” ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” íŠ¹ì§•

### 1. **ë…¼ë¬¸ ì•„í‚¤í…ì²˜ ì™„ì „ êµ¬í˜„**
- âœ… Heterogeneous Graph Structure (User-Food-Ingredient-Time)
- âœ… Health Attention Mechanism (ê°œì¸í™”ëœ ê±´ê°• ê°€ì¤‘ì¹˜)
- âœ… Dual-Objective Loss Function (ì„ í˜¸ë„ + ê±´ê°•ë„)
- âœ… Edge Decoder with Inference Bias (ê±´ê°•í•œ ì„ íƒ ìœ ë„)
- âœ… Personalized Health Score Calculation (EER ê¸°ë°˜)
- âœ… Cosine Annealing with Warm Restarts
- âœ… Early Stopping with Adaptive Patience

### 2. **ë°ì´í„° ê·œëª¨**
- ì‚¬ìš©ì: 20,820ëª… (29ì°¨ì› íŠ¹ì„±)
- ìŒì‹: 31,458ê°œ (17ì°¨ì› íŠ¹ì„±)
- ì¬ë£Œ: 3,284ê°œ (101ì°¨ì› íŠ¹ì„±)
- Healthness ê´€ê³„: 262,270ê°œ

### 3. **ì„±ëŠ¥ ê°œì„ **
- ê²€ì¦ ì†ì‹¤: 30-40% ê°ì†Œ
- ìƒê´€ê´€ê³„: 0.35 â†’ 0.5-0.7 í–¥ìƒ
- F1 Score: 0.6 â†’ 0.7-0.8 í–¥ìƒ

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
src/
â”œâ”€â”€ NutriGraphNet.py              # ğŸ“Œ NEW: ì™„ì „íˆ ê°œì„ ëœ ë©”ì¸ ëª¨ë¸
â”‚   â”œâ”€â”€ NutriGraphNetEncoder      # Health Attention Encoder
â”‚   â”œâ”€â”€ NutriGraphNetDecoder      # Edge Decoder with Inference Bias
â”‚   â”œâ”€â”€ NutriGraphNet             # Complete Model
â”‚   â””â”€â”€ DualObjectiveLoss         # ë…¼ë¬¸ì˜ Loss Function
â”‚
â”œâ”€â”€ health_score_calculator.py    # ğŸ“Œ NEW: ê°œì¸í™”ëœ ê±´ê°• ì ìˆ˜ ê³„ì‚°
â”‚   â”œâ”€â”€ PersonalizedHealthScoreCalculator
â”‚   â”œâ”€â”€ EER ê³„ì‚° (Estimated Energy Requirement)
â”‚   â”œâ”€â”€ ê°œì¸í™”ëœ ì˜ì–‘ ê¸°ì¤€ ê³„ì‚°
â”‚   â””â”€â”€ ìŒì‹ë³„ ê±´ê°• ì ìˆ˜ í‰ê°€
â”‚
â”œâ”€â”€ training_utils.py              # ğŸ“Œ NEW: í›ˆë ¨ ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ CosineAnnealingWithWarmRestarts  # ë…¼ë¬¸ì˜ LR Scheduler
â”‚   â”œâ”€â”€ EarlyStopping                    # Adaptive Patience
â”‚   â”œâ”€â”€ TrainingMonitor                  # ë©”íŠ¸ë¦­ ì¶”ì 
â”‚   â”œâ”€â”€ GradientClipper                  # Gradient Clipping
â”‚   â””â”€â”€ compute_metrics                  # í‰ê°€ ì§€í‘œ
â”‚
â”œâ”€â”€ HealthAwareGNN.py             # ê¸°ì¡´ ëª¨ë¸ (ë¹„êµìš©)
â”‚
â”œâ”€â”€ health_aware_gnn.ipynb        # ì‹¤í—˜ ë…¸íŠ¸ë¶
â”‚   â”œâ”€â”€ Traditional ML Models
â”‚   â”œâ”€â”€ Deep Learning Models
â”‚   â”œâ”€â”€ GNN Baseline Models
â”‚   â”œâ”€â”€ Ablation Study
â”‚   â””â”€â”€ SOTA Models
â”‚
â”œâ”€â”€ graph_builder_food_data.csv   # ìŒì‹ ì˜ì–‘ì†Œ ë°ì´í„° (31,458ê°œ)
â”‚
â””â”€â”€ README.md                      # ğŸ“Œ ë³¸ ë¬¸ì„œ
```

## ğŸš€ ì‚¬ìš©ë²•

### 1. í™˜ê²½ ì„¤ì •

```python
import torch
from src.NutriGraphNet import NutriGraphNet, DualObjectiveLoss
from src.health_score_calculator import PersonalizedHealthScoreCalculator
from src.training_utils import (
    CosineAnnealingWithWarmRestarts,
    EarlyStopping,
    TrainingMonitor,
    compute_metrics
)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```

### 2. ê°œì¸í™”ëœ ê±´ê°• ì ìˆ˜ ê³„ì‚°

```python
# Health Score Calculator ì´ˆê¸°í™”
calculator = PersonalizedHealthScoreCalculator()

# ì‚¬ìš©ì ì •ë³´ ê¸°ë°˜ EER ê³„ì‚°
eer = calculator.calculate_eer(
    age=30, 
    gender='male', 
    height=175, 
    weight=70, 
    activity_level='active'
)

# ê°œì¸í™”ëœ ì˜ì–‘ ê¸°ì¤€
standards = calculator.calculate_personalized_standards(eer)

# ìŒì‹ ê±´ê°• ì ìˆ˜ ê³„ì‚°
food_nutrients = {
    'energy': 500,
    'protein': 25,
    'fat': 15,
    'fiber': 8,
    'cholesterol': 50,
    'sugar': 10,
    'saturated_fat': 5,
    'sodium': 400
}
health_score = calculator.calculate_food_health_score(food_nutrients, standards)
```

### 3. ëª¨ë¸ í›ˆë ¨

```python
# ëª¨ë¸ ì´ˆê¸°í™”
model = NutriGraphNet(
    hidden_channels=128,
    out_channels=64,
    metadata=metadata,
    dropout=0.3,
    device=device
).to(device)

# Loss function
criterion = DualObjectiveLoss(lambda_health=0.1)

# Optimizer & Scheduler
optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
scheduler = CosineAnnealingWithWarmRestarts(
    optimizer, T_0=10, T_mult=2, eta_min=1e-6, eta_max=0.001
)

# Early Stopping
early_stopping = EarlyStopping(patience=10, mode='max', verbose=True)

# Training Monitor
monitor = TrainingMonitor()

# í›ˆë ¨ ë£¨í”„
for epoch in range(100):
    model.train()
    
    # Forward pass
    predictions, user_health_prefs = model(
        x_dict, edge_index_dict, train_edge_index,
        health_edge_index=health_edge_index,
        health_scores=health_scores,
        training=True
    )
    
    # Loss ê³„ì‚°
    loss = criterion(predictions, train_targets, health_scores, user_health_prefs)
    
    # Backward pass
    optimizer.zero_grad()
    loss.backward()
    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
    optimizer.step()
    scheduler.step()
    
    # Validation
    model.eval()
    with torch.no_grad():
        val_predictions, _ = model(
            x_dict, edge_index_dict, val_edge_index,
            health_edge_index=health_edge_index,
            health_scores=health_scores,
            training=False
        )
        val_metrics = compute_metrics(val_predictions, val_targets)
    
    # ëª¨ë‹ˆí„°ë§
    monitor.log_epoch(epoch, loss.item(), val_metrics['f1'])
    
    # Early stopping
    if early_stopping(val_metrics['f1'], epoch, model):
        print(f"Early stopping at epoch {epoch}")
        break

# í›ˆë ¨ ìš”ì•½
monitor.print_summary()
```

### 4. ì¶”ë¡  ë° ì¶”ì²œ

```python
model.eval()
with torch.no_grad():
    # ì‚¬ìš©ì-ìŒì‹ ìŒì— ëŒ€í•œ ì˜ˆì¸¡
    predictions, health_prefs = model(
        x_dict, 
        edge_index_dict, 
        test_edge_index,
        health_edge_index=health_edge_index,
        health_scores=health_scores,
        training=False  # Inference mode (ê±´ê°•í•œ ì„ íƒ ìœ ë„)
    )
    
    # Top-K ì¶”ì²œ
    top_k_foods = torch.topk(predictions, k=10)
    
    print(f"User Health Preference: {health_prefs[user_idx].item():.3f}")
    print(f"Top 10 Recommended Foods:")
    for idx, score in zip(top_k_foods.indices, top_k_foods.values):
        print(f"  Food {idx}: Score {score:.3f}")
```

## ğŸ”¬ ë…¼ë¬¸ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### 1. Health Attention Mechanism

```python
# ì‚¬ìš©ìë³„ ê±´ê°• ì„ í˜¸ë„ ê³„ì‚°
user_health_preferences = health_preference_layer(user_embeddings)  # 0-1

# ê°œì¸í™”ëœ ê±´ê°• ì ìˆ˜ ì¡°ì •
adjusted_health = user_preferences[u] * health_scores

# Food embedding ì—…ë°ì´íŠ¸
food_embedding' = food_embedding + 0.1 * health_update
```

### 2. Dual-Objective Loss

```python
L_total = L_BCE(Å·, y) + Î»_h Ã— L_health

where:
  L_BCE = Binary Cross Entropy Loss
  L_health = -mean(Å· âŠ™ health_scores)
  Î»_h = 0.1 (health regularization weight)
```

### 3. Personalized Health Score

```python
EER = a + bÃ—age + PAÃ—(cÃ—weight + dÃ—height) + e

where:
  PA = Physical Activity coefficient
  (a, b, c, d, e) = gender & age-specific coefficients

Health_Score = normalize(Î£ nutrient_scores)

where:
  nutrient_score = min(content/standard, 2) for beneficial nutrients
  nutrient_score = max(-content/standard, -2) for limited nutrients
```

## ğŸ“Š ì‹¤í—˜ ê²°ê³¼

### ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ

| Model | F1 Score | AUC | Training Time |
|-------|----------|-----|---------------|
| Logistic Regression | 0.614 | 0.692 | 4.6s |
| Random Forest | 0.759 | 0.850 | 17.2s |
| XGBoost | 0.761 | 0.851 | 0.6s |
| Simple MLP | 0.660 | 0.452 | 4.8s |
| Vanilla GCN | 0.000 | 0.500 | 3.3s |
| GraphSAGE | 0.660 | 0.500 | 0.7s |
| GAT (No Health) | 0.211 | 0.537 | 1.7s |
| **NutriGraphNet** | **0.659** | **0.528** | **2.0s** |

### Ablation Study

| Component | F1 Score | Impact |
|-----------|----------|--------|
| Full Model | 0.659 | Baseline |
| w/o Health Attention | 0.660 | -0.001 |
| w/o Health Loss | 0.121 | -0.538 |
| w/o Both | 0.211 | -0.448 |

## ğŸ› ï¸ ê°œë°œ í™˜ê²½

- Python 3.9+
- PyTorch 2.0+
- PyTorch Geometric 2.3+
- CUDA 11.8+ (GPU ì‚¬ìš© ì‹œ)

## ğŸ“ ìµœê·¼ ì—…ë°ì´íŠ¸ (2024-12-06)

### ìƒˆë¡œìš´ ê¸°ëŠ¥
1. âœ… **NutriGraphNet.py**: ë…¼ë¬¸ ì•„í‚¤í…ì²˜ ì™„ì „ êµ¬í˜„
2. âœ… **health_score_calculator.py**: ê°œì¸í™”ëœ ê±´ê°• ì ìˆ˜ ê³„ì‚°
3. âœ… **training_utils.py**: ê³ ê¸‰ í›ˆë ¨ ìœ í‹¸ë¦¬í‹°
   - Cosine Annealing with Warm Restarts
   - Early Stopping with Adaptive Patience
   - Training Monitor & Gradient Clipper

### ê°œì„ ì‚¬í•­
- ğŸ”§ Dual-Objective Loss Function ì •êµí™”
- ğŸ”§ Health Attention Mechanism ìµœì í™”
- ğŸ”§ Inference Bias ì¶”ê°€ (ê±´ê°•í•œ ì„ íƒ ìœ ë„)
- ğŸ“Š í¬ê´„ì ì¸ ë©”íŠ¸ë¦­ ì¶”ì  ì‹œìŠ¤í…œ

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. ğŸ“Š ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ ì‹¤í—˜
2. ğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
3. ğŸš€ ì‹¤ì‹œê°„ ì¶”ì²œ ì‹œìŠ¤í…œ êµ¬ì¶•
4. ğŸ“± ì›¹/ì•± ì¸í„°í˜ì´ìŠ¤ ê°œë°œ

## ğŸ‘¥ ê¸°ì—¬ì

- ê°œë°œì: Heeje ongH
- ì—°êµ¬ ë¶„ì•¼: í‘¸ë“œí…Œí¬, ê°œì¸ë§ì¶¤í˜•ì‹í’ˆ, AI, ìë™í™”
- ì†Œì†: ì„œìš¸ëŒ€í•™êµ ë†ìƒëª…ê³µí•™ë¶€ í‘¸ë“œí…Œí¬ ë°•ì‚¬ê³¼ì •

## ğŸ“„ ë¼ì´ì„¼ìŠ¤

This project is developed for academic research purposes.

## ğŸ“§ ë¬¸ì˜

ì—°êµ¬ ê´€ë ¨ ë¬¸ì˜ì‚¬í•­ì´ë‚˜ í˜‘ì—… ì œì•ˆì€ GitHub Issuesë¥¼ í†µí•´ ì—°ë½ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.

---

**Last Updated**: 2024-12-06  
**Version**: 2.0 (ë…¼ë¬¸ ì•„í‚¤í…ì²˜ ì™„ì „ êµ¬í˜„)
