"""
ê°„ë‹¨í•œ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸
í…ŒìŠ¤íŠ¸ ë° ë°ëª¨ìš©
"""

import numpy as np
import torch
import pickle
from pathlib import Path
import sys
sys.path.append('src')
from simple_hetero_data import SimpleHeteroData

def create_sample_data(
    num_users=1000,
    num_foods=1000,
    num_ingredients=100,
    num_interactions=10000,
    save_path='../data/processed_data/processed_data_GNN.pkl'
):
    """
    í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    
    Args:
        num_users: ì‚¬ìš©ì ìˆ˜
        num_foods: ìŒì‹ ìˆ˜
        num_ingredients: ì¬ë£Œ ìˆ˜
        num_interactions: ì‚¬ìš©ì-ìŒì‹ ìƒí˜¸ì‘ìš© ìˆ˜
        save_path: ì €ì¥ ê²½ë¡œ
    """
    
    print("ğŸ“Š Creating sample data...")
    print(f"   Users: {num_users:,}")
    print(f"   Foods: {num_foods:,}")
    print(f"   Ingredients: {num_ingredients:,}")
    print(f"   Interactions: {num_interactions:,}")
    
    # ë…¸ë“œ íŠ¹ì„± ìƒì„±
    user_features = np.random.randn(num_users, 29).astype(np.float32)
    food_features = np.random.randn(num_foods, 17).astype(np.float32)
    ingredient_features = np.random.randn(num_ingredients, 101).astype(np.float32)
    time_features = np.eye(4, dtype=np.float32)
    
    # ì‚¬ìš©ì-ìŒì‹ ìƒí˜¸ì‘ìš©
    user_indices = np.random.randint(0, num_users, num_interactions)
    food_indices = np.random.randint(0, num_foods, num_interactions)
    eats_scores = np.random.beta(2, 2, num_interactions).astype(np.float32)
    
    # ê±´ê°• ì ìˆ˜ (ìŒì‹ íŠ¹ì„± ê¸°ë°˜)
    health_scores = 0.3 + 0.6 * np.random.beta(5, 2, num_interactions).astype(np.float32)
    
    # ìŒì‹-ì¬ë£Œ ì—°ê²°
    num_food_ing = min(5000, num_foods * 5)
    food_ing_food = np.random.randint(0, num_foods, num_food_ing)
    food_ing_ing = np.random.randint(0, num_ingredients, num_food_ing)
    
    # ìŒì‹-ì‹œê°„ ì—°ê²°
    num_food_time = min(3000, num_foods * 3)
    food_time_food = np.random.randint(0, num_foods, num_food_time)
    food_time_time = np.random.randint(0, 4, num_food_time)
    
    # HeteroData ìƒì„±
    data = SimpleHeteroData()
    
    # ë…¸ë“œ íŠ¹ì„±
    data.x_dict = {
        'user': torch.FloatTensor(user_features),
        'food': torch.FloatTensor(food_features),
        'ingredient': torch.FloatTensor(ingredient_features),
        'time': torch.FloatTensor(time_features)
    }
    
    # ì—£ì§€ ì¸ë±ìŠ¤
    eats_edge = torch.LongTensor(np.stack([user_indices, food_indices]))
    data.edge_index_dict[('user', 'eats', 'food')] = eats_edge
    data.edge_attr_dict[('user', 'eats', 'food')] = torch.FloatTensor(eats_scores)
    
    data.edge_index_dict[('food', 'rev_eats', 'user')] = torch.stack([
        eats_edge[1], eats_edge[0]
    ])
    
    # ê±´ê°• ì—£ì§€
    health_edge = torch.LongTensor(np.stack([user_indices, food_indices]))
    data.edge_index_dict[('user', 'healthness', 'food')] = health_edge
    data.edge_attr_dict[('user', 'healthness', 'food')] = torch.FloatTensor(health_scores)
    
    data.edge_index_dict[('food', 'rev_healthness', 'user')] = torch.stack([
        health_edge[1], health_edge[0]
    ])
    
    # ìŒì‹-ì¬ë£Œ ì—£ì§€
    food_ing_edge = torch.LongTensor(np.stack([food_ing_food, food_ing_ing]))
    data.edge_index_dict[('food', 'contains', 'ingredient')] = food_ing_edge
    data.edge_index_dict[('ingredient', 'rev_contains', 'food')] = torch.stack([
        food_ing_edge[1], food_ing_edge[0]
    ])
    
    # ìŒì‹-ì‹œê°„ ì—£ì§€
    food_time_edge = torch.LongTensor(np.stack([food_time_food, food_time_time]))
    data.edge_index_dict[('food', 'eaten_at', 'time')] = food_time_edge
    data.edge_index_dict[('time', 'rev_eaten_at', 'food')] = torch.stack([
        food_time_edge[1], food_time_edge[0]
    ])
    
    # ìŒì‹-ìŒì‹ ìœ ì‚¬ë„
    num_similar = min(1000, num_foods)
    food_sim_1 = np.random.randint(0, num_foods, num_similar)
    food_sim_2 = np.random.randint(0, num_foods, num_similar)
    data.edge_index_dict[('food', 'similar', 'food')] = torch.LongTensor(
        np.stack([food_sim_1, food_sim_2])
    )
    
    # ID ë§¤í•‘
    data.user_id_mapping = {i: i for i in range(num_users)}
    data.food_id_mapping = {i: i for i in range(num_foods)}
    
    # ì €ì¥
    output_path = Path(save_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'wb') as f:
        pickle.dump(data, f)
    
    print(f"\nâœ… Sample data created: {output_path}")
    print(f"   File size: {output_path.stat().st_size / 1024 / 1024:.2f} MB")
    print(f"\nğŸ‰ Ready to train!")
    print(f"   Run: python train_v2.py --epochs 30")
    
    return data

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='Create sample data for testing')
    parser.add_argument('--num_users', type=int, default=1000, help='Number of users')
    parser.add_argument('--num_foods', type=int, default=1000, help='Number of foods')
    parser.add_argument('--num_ingredients', type=int, default=100, help='Number of ingredients')
    parser.add_argument('--num_interactions', type=int, default=10000, help='Number of interactions')
    parser.add_argument('--save_path', type=str, 
                       default='../data/processed_data/processed_data_GNN.pkl',
                       help='Save path')
    
    args = parser.parse_args()
    
    create_sample_data(
        num_users=args.num_users,
        num_foods=args.num_foods,
        num_ingredients=args.num_ingredients,
        num_interactions=args.num_interactions,
        save_path=args.save_path
    )
